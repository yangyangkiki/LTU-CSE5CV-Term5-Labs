{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00e49e70-0bd8-48be-ac87-8517ca4cde1b",
      "metadata": {
        "id": "00e49e70-0bd8-48be-ac87-8517ca4cde1b"
      },
      "source": [
        "# CSE5CV - Azure Services\n",
        "\n",
        "In this weeks lab we'll have a crash course on training and using computer vision models with Microsoft Azure. Specifically:\n",
        "\n",
        "* Understand Azure terms like \"Cognitive Services\", \"resources\", etc.\n",
        "* Fine-tune an image classification model to classify fruit.\n",
        "* Train and deploy models onto Azure with zero code.\n",
        "* Interact with deployed models with python.\n",
        "* Use various other Cognitive Services available through Azure:\n",
        "    * Image captioning\n",
        "    * Optical Character Recognition\n",
        "    * Face Detection\n",
        "* A brief discussion of ethics in AI with respect to evaluating emotion from images."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Colab preparation\n",
        "\n",
        "Google Colab is a free online service for editing and running code in notebooks like this one. To get started, follow the steps below:\n",
        "\n",
        "1. Click the \"Copy to Drive\" button at the top of the page. This will open a new tab with the title \"Copy of...\". This is a copy of the lab notebook which is saved in your personal Google Drive. **Continue working in that copy, otherwise you will not be able to save your work**. You may close the original Colab page (the one which displays the \"Copy to Drive\" button).\n",
        "2. Run the code cell below to prepare the Colab coding environment by downloading sample files. Note that if you close this notebook and come back to work on it again later, you will need to run this cell again."
      ],
      "metadata": {
        "id": "qHrEAKS4h2Nm"
      },
      "id": "qHrEAKS4h2Nm"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ltu-cse5cv/cse5cv-labs.git\n",
        "%cd cse5cv-labs/Lab09"
      ],
      "metadata": {
        "id": "wM8UKEozh4MK"
      },
      "execution_count": null,
      "outputs": [],
      "id": "wM8UKEozh4MK"
    },
    {
      "cell_type": "markdown",
      "id": "64c476ea-5402-41c5-beba-73220f81ac06",
      "metadata": {
        "id": "64c476ea-5402-41c5-beba-73220f81ac06"
      },
      "source": [
        "## Packages\n",
        "\n",
        "This week we're introducing some new packages for communicating with Azure from Python scripts.\n",
        "\n",
        "You will need to install additional pip packages which provide support for Azure. The code in the following cell will install these packages in the notebook environment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install azure-cognitiveservices-vision-customvision~=3.1.0 \\\n",
        "             azure-cognitiveservices-vision-computervision~=0.9.0 \\\n",
        "             azure-ai-formrecognizer~=3.1.2"
      ],
      "metadata": {
        "id": "g12W-5ePrFdn"
      },
      "id": "g12W-5ePrFdn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2888d8d4-4a98-4bbb-9320-94d3b0dd5997",
      "metadata": {
        "id": "2888d8d4-4a98-4bbb-9320-94d3b0dd5997"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
        "from azure.ai.formrecognizer import FormRecognizerClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from msrest.authentication import ApiKeyCredentials, CognitiveServicesCredentials\n",
        "\n",
        "# Utility functions\n",
        "def load_image_rgb(filepath):\n",
        "    image = cv2.imread(filepath)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image\n",
        "\n",
        "def display_image(image, title=None):\n",
        "    fig, axes = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    if image.ndim == 2:\n",
        "        axes.imshow(image, cmap='gray', vmin=0, vmax=255)\n",
        "    else:\n",
        "        axes.imshow(image)\n",
        "\n",
        "    axes.axis('off')\n",
        "\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c58308c-84dc-405e-9fc9-9b78663ea1b5",
      "metadata": {
        "id": "7c58308c-84dc-405e-9fc9-9b78663ea1b5"
      },
      "source": [
        "### Azure Python SDK\n",
        "Provides extremely simple access to the Custom Vision and Cognitive Services through python. Behind the scenes, the objects perform REST requests to the servers.\n",
        "\n",
        "This SDK is split up over several different python packages. We use 4 different packages in this lab:\n",
        "\n",
        "1. `azure-cognitiveservices-vision-customvision`: for CustomVisionPredictionClient.\n",
        "2. `azure-cognitiveservices-vision-computervision`: for ComputerVisionClient.\n",
        "4. `azure-ai-formrecognizer`: for FormRecognizerClient.\n",
        "\n",
        "Note that the credentials are pre-requisites of the above packages and were installed alongside the above packages.\n",
        "\n",
        "Package Homepage: https://github.com/Azure/azure-sdk-for-python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "851b3b93-df87-4fd5-8a2c-3de36bb694bc",
      "metadata": {
        "id": "851b3b93-df87-4fd5-8a2c-3de36bb694bc"
      },
      "source": [
        "# 1. Azure introduction\n",
        "\n",
        "Microsoft Azure is a cloud provider with sophisticated UIs and libraries to create and deploy various machine learning models to publicly available URLs. If you wanted to create an app that classifies images from your phone's camera, you could use Azure to host the computer vision model that does that classification on the cloud.\n",
        "\n",
        "Microsoft Azure has some terminology we would like to highlight to you:\n",
        "\n",
        "**Free tier**: Cloud providers will charge you for using their services. There is a free tier for students with Azure. You should be careful to only do the tasks we describe, and careful to clean up your provisioned resources.\n",
        "\n",
        "**Resource**: In this lab, a virtual machine for running jobs hosted on Azure's cloud infrastructure.\n",
        "\n",
        "**Custom Vision Resource**: A type of resource provided by Azure for easily creating custom cloud-hosted computer vision models. We don't need to configure it at all, we just need to populate it with models (see Section 2).\n",
        "\n",
        "**Cognitive Services Resource**: A type of resource provided by Azure for performing some predefined operations on images using AI:\n",
        "  * Image captioning.\n",
        "  * Image detection.\n",
        "  * Location and approximate age of human faces in the image.\n",
        "  * Automatic tagging.\n",
        "    * Whether the image contains any 'adult', 'racy', or 'gory' content.\n",
        "\n",
        "\n",
        "**Resource Group**: Your resources are organised into \"Resource groups\". These are groups of virtual machines that work together on whatever you like. When you create a Custom Vision resource, Azure creates two resources at once: a \"training\" and \"prediction\" resource. Your running resources can be viewed here: https://portal.azure.com/#blade/HubsExtension/BrowseResourceGroups\n",
        "\n",
        "**Project**: The training/deployment of a single computer vision model onto a resource.\n",
        "\n",
        "**Model**: Just like we have done in the labs, a \"model\" is a function which takes an image and produces predictions. In this case, a model will be trained and deployed to a resource, and interacted with using a REST API through a Custom Vision client object (see Section 2)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bfd3799-46ea-4650-b14a-9be28477b210",
      "metadata": {
        "id": "6bfd3799-46ea-4650-b14a-9be28477b210"
      },
      "source": [
        "## 1.1 Create resources/resource group\n",
        "\n",
        "This lab is split up into several \"projects\". These projects will share the same Azure \"resources\". So, you will only need to create these resources once for this lab, and they will be re-used for all the projects. However, when you are done with the lab, make sure you remove those resources (see Section 1.2).\n",
        "\n",
        "**Task**: Create two resources in a single resource group. We will create a \"Custom Vision\" and a \"Cognitive Services\" resource for use in this lab. We will first go through creating a \"Custom Vision\" resource and then creating a \"Cognitive Services\" resource.\n",
        "\n",
        "The starting point for creating any resource on Azure is to visit: https://portal.azure.com. Make sure you are logged in with your new account (use a separate private window if you need)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44588c33-4eef-4993-856b-899a92c393aa",
      "metadata": {
        "id": "44588c33-4eef-4993-856b-899a92c393aa"
      },
      "source": [
        "### 1.1.1 Custom Vision\n",
        "\n",
        "Starting from: https://portal.azure.com:\n",
        "\n",
        "1. Click \"Create a Resource\"\n",
        "2. Search for \"Custom Vision\"\n",
        "3. Select \"Custom Vision\" and then click \"Create\"\n",
        "4. Create a new resource group by clicking \"Create new\" under \"Resource Group\". Name it \"CSE5CV-Azure\".\n",
        "5. Enter a unique instance name including your student ID and \"customvision\". For example, `22222222customvision`.\n",
        "6. Select the free tier for both training and prediction.\n",
        "7. Click \"Review + Create\". Then click \"Create\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6665829c-77b0-46a4-abd2-584be8311ef3",
      "metadata": {
        "id": "6665829c-77b0-46a4-abd2-584be8311ef3"
      },
      "source": [
        "### 1.1.2 Cognitive Services\n",
        "\n",
        "Starting from: https://portal.azure.com\n",
        "\n",
        "1. Click \"Create a Resource\".\n",
        "2. Search \"Cognitive Services\".\n",
        "3. Click \"Create\"\n",
        "4. Assign the Cognitive Services resource to the same resource group as before.\n",
        "5. Enter a unique instance name including your student ID and \"cognitiveservices\". For example, `22222222cognitiveservices`.\n",
        "6. Read and if you accept the conditions, tick the box.\n",
        "7. Review and create"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69640eb8-2a57-43d5-800c-893b2f9dd546",
      "metadata": {
        "id": "69640eb8-2a57-43d5-800c-893b2f9dd546"
      },
      "source": [
        "## 1.2 Deleting resource groups\n",
        "\n",
        "**Important**: **To do only when you are done with this lab**\n",
        "\n",
        "*When you are done with this lab* you can follow these instructions to delete your resource group. This will remove all of the resources you created in one go: the Custom Vision resources and the Cognitive Services resources.\n",
        "\n",
        "1. Visit https://portal.azure.com/#blade/HubsExtension/BrowseResourceGroups.\n",
        "2. Select resource group (click the name)\n",
        "3. Click \"Delete resource group\"\n",
        "4. Enter the name \"CSE5CV-Azure\" (this is a clever UI to ensure that you are deleting the resource group you intend to).\n",
        "5. Click \"Delete\".\n",
        "\n",
        "![Deleting resource group](https://github.com/ltu-cse5cv/cse5cv-labs/blob/master/Lab09/img/present/delete-resource-group.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd712b19-748d-4515-a538-73a69f98cc80",
      "metadata": {
        "id": "bd712b19-748d-4515-a538-73a69f98cc80"
      },
      "source": [
        "## 1.3 Collect communication credentials\n",
        "\n",
        "These resources come pre-configured to receive REST requests. However, they are not open to the world; you need to use specific credentials to access them. Here we describe how to get the credentials for each of the resources."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "043a877b-2213-4100-a990-8baa8da8b294",
      "metadata": {
        "id": "043a877b-2213-4100-a990-8baa8da8b294"
      },
      "source": [
        "### 1.3.1 Custom Vision\n",
        "\n",
        "We will eventually create models for the \"Custom Vision\" resources to use for prediction. We will choose which model to access using the project id and model's name. However, all of the REST requests will go to the same resource using the same credentials.\n",
        "\n",
        "**Task**: Collect your custom vision resource's REST credentials from Azure.\n",
        "\n",
        "1. Visit http://portal.azure.com\n",
        "2. Search \"All Resources\" in the top bar\n",
        "3. Select the \"Custom vision\" item ending in \"-Prediction\" (click its name)\n",
        "4. Select \"Keys and Endpoint\"\n",
        "5. Copy \"Key 1\" and \"Endpoint\" into `custom_vision_key` and `custom_vision_endpoint` respectively in the next code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1bf3ff6-3b6b-4be1-8fc5-7e85d86fe807",
      "metadata": {
        "id": "f1bf3ff6-3b6b-4be1-8fc5-7e85d86fe807"
      },
      "outputs": [],
      "source": [
        "# TODO: fill with your data\n",
        "custom_vision_key = ''\n",
        "custom_vision_endpoint = ''\n",
        "\n",
        "custom_vision_credentials = ApiKeyCredentials(\n",
        "    in_headers={\"Prediction-key\": custom_vision_key}\n",
        ")\n",
        "custom_vision_client = CustomVisionPredictionClient(\n",
        "    endpoint=custom_vision_endpoint,\n",
        "    credentials=custom_vision_credentials\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d86f102a-48a2-4687-b301-af10d2c53bda",
      "metadata": {
        "id": "d86f102a-48a2-4687-b301-af10d2c53bda"
      },
      "source": [
        "Now we have an object `custom_vision_client` which can interact with our hosted resource very easily. Eventually we will be calling `custom_vision_client.classify_image()`, but first we need to host/deploy a model on the resource."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fedc2b3-81f8-43e5-b2f9-c2603fd64955",
      "metadata": {
        "id": "2fedc2b3-81f8-43e5-b2f9-c2603fd64955"
      },
      "source": [
        "### 1.3.2 Cognitive Services\n",
        "\n",
        "**Task**: Collect your cognitive services resource's REST credentials from Azure.\n",
        "\n",
        "1. Visit http://portal.azure.com\n",
        "2. Search \"All Resources\" in the top bar\n",
        "3. Select the \"Cognitive services multi-service account\" item (click its name)\n",
        "4. Select \"Keys and Endpoint\"\n",
        "\n",
        "![Cognitive services credentials](https://github.com/ltu-cse5cv/cse5cv-labs/blob/master/Lab09/img/present/credentials-cognitive-services.png?raw=1)\n",
        "\n",
        "5. Copy \"Key 1\" and \"Endpoint\" into `cog_key` and `cog_endpoint` respectively in the next code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d48b2044-656f-4f57-9c6c-c1c1638d5f1f",
      "metadata": {
        "id": "d48b2044-656f-4f57-9c6c-c1c1638d5f1f"
      },
      "outputs": [],
      "source": [
        "# TODO: Copy values into the following variables\n",
        "cog_key = ''\n",
        "cog_endpoint = ''\n",
        "\n",
        "# Initialise credential objects\n",
        "cog_credentials = CognitiveServicesCredentials(cog_key)\n",
        "key_credentials = AzureKeyCredential(cog_key)\n",
        "\n",
        "# Instantiate client objects for interaction with Cognitive Services server\n",
        "cog_client = ComputerVisionClient(cog_endpoint, cog_credentials)\n",
        "form_rec_client = FormRecognizerClient(cog_endpoint, key_credentials)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bdc6210-1f40-4952-9a25-6d1599015a50",
      "metadata": {
        "id": "7bdc6210-1f40-4952-9a25-6d1599015a50"
      },
      "source": [
        "# 2. Classify fruit\n",
        "\n",
        "We will use a Custom Vision web interface provided by Azure to train a fruit classification model. After we create the model, we will deploy it onto our Custom Vision resource, and send images to be classified from this notebook using a REST API through the `custom_vision_client` we created in section 1.3.1.\n",
        "\n",
        "This project operates entirely within free services, and will not deduct from your credits."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44c30de8-b34a-4fba-a3f7-a8abc47bc64d",
      "metadata": {
        "id": "44c30de8-b34a-4fba-a3f7-a8abc47bc64d"
      },
      "source": [
        "## 2.1 Create a new project\n",
        "\n",
        "Visit: https://www.customvision.ai\n",
        "\n",
        "The free tier of Azure only allows you to have one free project running at once. Make sure you have closed any other projects.\n",
        "\n",
        "**Task**: Create a new project with the following settings:\n",
        "* **Name**: Fruit Classifier\n",
        "* **Description**: Image classification for fruit\n",
        "* **Resource**: (select the name of your Custom Vision resource that you created at the start)\n",
        "* **Project Types**: Classification\n",
        "* **Classification Types**: Multiclass\n",
        "* **Domains**: Food"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9acb246-f9af-48e4-9f81-e76a2595c22f",
      "metadata": {
        "id": "c9acb246-f9af-48e4-9f81-e76a2595c22f"
      },
      "source": [
        "## 2.2 Upload training images\n",
        "\n",
        "**Task**: Upload all of your training images.\n",
        "1. Download and extract the following .zip archive containing fruit images: https://github.com/ltu-cse5cv/cse5cv-labs/releases/download/v0.0.0/fruit.zip\n",
        "2. Back on the Custom Vision web page, click \"Add images\".\n",
        "3. Navigate to `fruit/train/apple`. Use shift to select all the images in this folder. Type \"apple\" into the \"My Tags\" field.\n",
        "4. Repeat steps 1 and 2 for \"banana\" and \"orange\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7467693c-f35e-42a3-9f8b-d18c11a013c7",
      "metadata": {
        "id": "7467693c-f35e-42a3-9f8b-d18c11a013c7"
      },
      "source": [
        "**Question**: How many training images do we have? How many classes?\n",
        "\n",
        "<details>\n",
        "<summary style='cursor:pointer;'><u>Answer</u></summary>\n",
        "\n",
        "We have 45 training images over 3 classes: \"apple\", \"banana\", \"orange\" (15 images each).\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb263e33-6a1e-4ec2-a2ac-eb6d000b4778",
      "metadata": {
        "id": "fb263e33-6a1e-4ec2-a2ac-eb6d000b4778"
      },
      "source": [
        "## 2.3 Train model\n",
        "\n",
        "**Task**: Click the green \"Train\" button in the top-right. Choose \"Quick Training\". Click \"Train\".\n",
        "\n",
        "While it is training, we will collect the project id.\n",
        "\n",
        "**Task**: Click the cog in the top-right to get to the project settings. You will see the \"Project id\" like this:\n",
        "\n",
        "![Fruit project id](https://github.com/ltu-cse5cv/cse5cv-labs/blob/master/Lab09/img/present/fruit-project-id.png?raw=1)\n",
        "\n",
        "Record the \"Project Id\" in the `project_id` variable in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a63d67e-56de-4394-be4c-bced7ac975a3",
      "metadata": {
        "id": "8a63d67e-56de-4394-be4c-bced7ac975a3"
      },
      "outputs": [],
      "source": [
        "# TODO: Fill in project id\n",
        "project_id = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "636d2cd4-0fda-4ff6-bc8c-c4b5a84f1b82",
      "metadata": {
        "id": "636d2cd4-0fda-4ff6-bc8c-c4b5a84f1b82"
      },
      "source": [
        "**Task**: Click \"Performance\" in the top-right. Wait patiently for your model to finish training. It will take about 5 minutes. Do some breathing exercises. Meditate. Whatever."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b559ec6-eace-467d-881a-c6f002ceb774",
      "metadata": {
        "id": "1b559ec6-eace-467d-881a-c6f002ceb774"
      },
      "source": [
        "## 2.4 Deploy model\n",
        "\n",
        "When your model has finished training you will be presented with a page showing precision, recall, and AP performance metrics.\n",
        "\n",
        "**Task**: Click \"Publish\". Choose the model name \"fruit1\" and your prediction resource.\n",
        "\n",
        "In the next cell we interact with the model that we just trained and published/deployed on our resource. Publishing is instant; you can run the next cell right away."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f429f2b-e1fb-42d5-9903-5c0cd7c21c5a",
      "metadata": {
        "id": "7f429f2b-e1fb-42d5-9903-5c0cd7c21c5a"
      },
      "outputs": [],
      "source": [
        "model_name = 'fruit1'\n",
        "\n",
        "with open(Path('fruit', 'test', 'IMG_TEST_1.jpg'), 'rb') as f:\n",
        "    response = custom_vision_client.classify_image(project_id, model_name, f.read())\n",
        "\n",
        "# The predictions are returned in descending order of probability,\n",
        "# so we choose the first as the \"prediction\"\n",
        "print('The whole response:    -------')\n",
        "print(response)\n",
        "print('------------------------------')\n",
        "print()\n",
        "print('Our model predicted: ', response.predictions[0].tag_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12a85563-06c1-4ee3-a5eb-68c61b375bc0",
      "metadata": {
        "id": "12a85563-06c1-4ee3-a5eb-68c61b375bc0"
      },
      "source": [
        "**Question**: If we get more training data, how should we use this interface to train a new model and publish it? How will we tell the resource that we want to use the new model?\n",
        "\n",
        "<details>\n",
        "<summary style='cursor:pointer;'><u>Answer</u></summary>\n",
        "\n",
        "We would add new images under the \"Training Images\" tab, making sure to label them all. Then, we can run \"Quick Train\" again, training a new model on the whole dataset. When we publish, we must call it something else. Perhaps \"fruit2\". Then, when we call `custom_vision-client.classify_image(...)`, we need to make sure we pass the correct `model_name`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61ba2608-9ac6-42f7-8d57-96c2f283b27e",
      "metadata": {
        "id": "61ba2608-9ac6-42f7-8d57-96c2f283b27e"
      },
      "source": [
        "## 2.5 Test model\n",
        "\n",
        "Next we will visually evaluate all of our test images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3724296-8232-49ee-b3d2-a36b1de00fe7",
      "metadata": {
        "id": "f3724296-8232-49ee-b3d2-a36b1de00fe7"
      },
      "outputs": [],
      "source": [
        "test_image_paths = list(Path('fruit', 'test').iterdir())\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "cols = 3\n",
        "rows = len(test_image_paths)//cols\n",
        "\n",
        "for i, fpath in enumerate(test_image_paths):\n",
        "    # Get prediction from our service\n",
        "    with open(fpath, 'rb') as f:\n",
        "        response = custom_vision_client.classify_image(project_id, model_name, f.read())\n",
        "    pred = response.predictions[0].tag_name\n",
        "\n",
        "    # Load image data into numpy array with opencv\n",
        "    img = load_image_rgb(str(fpath))\n",
        "\n",
        "    # Display the image with it's prediction\n",
        "    ax = fig.add_subplot(rows, cols, i+1)\n",
        "    ax.axis('off')\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(pred)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da304455-54db-4051-ab99-6c03817cb272",
      "metadata": {
        "id": "da304455-54db-4051-ab99-6c03817cb272"
      },
      "source": [
        "**Question**: How did the model do?\n",
        "\n",
        "<details>\n",
        "<summary style='cursor:pointer;'><u>Answer</u></summary>\n",
        "\n",
        "Tutor: My model got all of them correct. This is a relatively easy task for modern deep learning, but, still. Good job, model!\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78e8baf5-00f1-438b-a86c-5ea8301fd5a4",
      "metadata": {
        "id": "78e8baf5-00f1-438b-a86c-5ea8301fd5a4"
      },
      "source": [
        "## 2.6 Summary\n",
        "\n",
        "You used www.customvision.ai to upload a training set for image classification, train a model and deploy it on Azure infrastructure. This model was accessible through a REST client. Azure provides a simple wrapper for us to use to communicate: `custom_vision_client`. In each request, we provided: `project_id`, `model_name` and some image data, and got back a prediction. Finally, we checked that it was working by sending unseen images."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac565679-4de8-404b-8104-81c7cf34ee0c",
      "metadata": {
        "id": "ac565679-4de8-404b-8104-81c7cf34ee0c"
      },
      "source": [
        "## 2.7 Remove Project\n",
        "\n",
        "The free tier only allows up to 2 projects active at once. Here are the instructions for removing this project.\n",
        "\n",
        "1. Unpublish all of your models\n",
        "2. Click the eye in the top left\n",
        "3. Hover over your \"Fruit Classifier\" project and click the trash can"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87c5b2a1-0db3-4441-9037-340fbf04f0bf",
      "metadata": {
        "id": "87c5b2a1-0db3-4441-9037-340fbf04f0bf"
      },
      "source": [
        "# 3. Describe Images\n",
        "\n",
        "We will use our Cognitive Services resource to show off some simple use cases.\n",
        "\n",
        "This project will deduct a small amount of credit from your free credits (\\<$1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f38f2e73-806c-4b28-bd75-6d6fd3121bdb",
      "metadata": {
        "id": "f38f2e73-806c-4b28-bd75-6d6fd3121bdb"
      },
      "outputs": [],
      "source": [
        "def load_and_detect(fpath, service):\n",
        "    img = load_image_rgb(str(fpath))\n",
        "    with open(fpath, 'rb') as f:\n",
        "        detections = service(f)\n",
        "    return img, detections\n",
        "\n",
        "def display_image(img, figsize=(15, 10)):\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b9976cf-2022-4c12-b271-ccc67c66136b",
      "metadata": {
        "id": "6b9976cf-2022-4c12-b271-ccc67c66136b"
      },
      "source": [
        "## 3.1 Image captioning\n",
        "\n",
        "**Task**: Run the next code cell to use the Cognitive Services to obtain a text description of `'face/store_cam2.jpg'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bfcda97-a797-4a4d-8ab9-6af758ce55cd",
      "metadata": {
        "id": "1bfcda97-a797-4a4d-8ab9-6af758ce55cd"
      },
      "outputs": [],
      "source": [
        "image_fpath = Path('face', 'store_cam2.jpg')\n",
        "img, description = load_and_detect(image_fpath, cog_client.describe_image_in_stream)\n",
        "\n",
        "print(description.captions[0].text)\n",
        "display_image(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b28d108a-7869-4f1b-8d8e-96b447b00f6d",
      "metadata": {
        "id": "b28d108a-7869-4f1b-8d8e-96b447b00f6d"
      },
      "source": [
        "**Question**: Which line of code executes a REST request in the above code?\n",
        "    \n",
        "<details>\n",
        "<summary style='cursor:pointer;'><u>Answer</u></summary>\n",
        "\n",
        "The function call `cog_client.describe_image_in_stream(f)` executes a REST request to the Cognitive Services resource that we created at the beginning of the lab.\n",
        "</details>\n",
        "<br />\n",
        "\n",
        "**Question**: Which line of code executes a REST request in the `load_and_detect` function above?\n",
        "    \n",
        "<details>\n",
        "<summary style='cursor:pointer;'><u>Answer</u></summary>\n",
        "\n",
        "The function call `service(f)` executes a REST request to the Cognitive Services resource that we created at the beginning of the lab. When a service call just requires the image, we'll use `load_and_detect` for brevity.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50e69cf5-640f-4c26-b627-a839cc0a34d7",
      "metadata": {
        "id": "50e69cf5-640f-4c26-b627-a839cc0a34d7"
      },
      "source": [
        "## 3.2 Object Detection\n",
        "\n",
        "We can get the Cognitive Services resource to detect objects in our images. Unlike when we used MaskRCNN, the model is on their server, and we send the image to the server. Apart from that, it's very similar; we provide an image, we get detections back out, and we don't need to train anything ourselves, and we get pretty good results immediately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14701e7e-f764-4acd-b056-cd37d5676433",
      "metadata": {
        "id": "14701e7e-f764-4acd-b056-cd37d5676433"
      },
      "outputs": [],
      "source": [
        "# Taken from Lab 4 (small modification to annotate_class)\n",
        "COLOURS = [\n",
        "    tuple(int(colour_hex.strip('#')[i:i+2], 16) for i in (0, 2, 4))\n",
        "    for colour_hex in plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "]\n",
        "\n",
        "def draw_detections(img, dets, colours=COLOURS):\n",
        "    for i, (cl, tlx, tly, brx, bry) in enumerate(dets):\n",
        "        i %= len(colours)\n",
        "        cv2.rectangle(img, (tlx, tly), (brx, bry), color=colours[i], thickness=2)\n",
        "\n",
        "def annotate_class(img, dets, conf=None, colours=COLOURS):\n",
        "    for i, (cl, tlx, tly, brx, bry) in enumerate(dets):\n",
        "        txt = cl\n",
        "        if conf is not None:\n",
        "            txt += f' {conf[i]:1.3f}'\n",
        "        # A box with a border thickness draws half of that thickness to the left of the\n",
        "        # boundaries, while filling fills only within the boundaries, so we expand the filled\n",
        "        # region to match the border\n",
        "        offset = 1\n",
        "\n",
        "        cv2.rectangle(img,\n",
        "                      (tlx-offset, tly-offset-12),\n",
        "                      (tlx-offset+len(txt)*12, tly),\n",
        "                      color=colours[i],\n",
        "                      thickness=cv2.FILLED)\n",
        "\n",
        "        ff = cv2.FONT_HERSHEY_PLAIN\n",
        "        cv2.putText(img, txt, (tlx, tly-1), fontFace=ff, fontScale=1.0, color=(255,)*3)\n",
        "\n",
        "# Useful functions for Azure responses\n",
        "def annotate_faces(img, dets, get_txt=None):\n",
        "    faces = []\n",
        "    for face in dets:\n",
        "        r = face.face_rectangle\n",
        "        tlx, tly, bw, bh = r.left, r.top, r.width, r.height\n",
        "        txt = get_txt(face) if get_txt is not None else None\n",
        "        faces.append((txt, tlx, tly, tlx+bw, tly+bh))\n",
        "    draw_detections(img, faces)\n",
        "    if get_txt is not None:\n",
        "        annotate_class(img, faces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0c5303f-460d-4e66-9162-448ce28f7fd2",
      "metadata": {
        "id": "b0c5303f-460d-4e66-9162-448ce28f7fd2"
      },
      "outputs": [],
      "source": [
        "# Get image and analysis\n",
        "image_fpath = Path('face', 'store_cam2.jpg')\n",
        "img = load_image_rgb(str(image_fpath))\n",
        "features = ['Description', 'Tags', 'Adult', 'Objects', 'Faces']\n",
        "with open(image_fpath, 'rb') as f:\n",
        "    analysis = cog_client.analyze_image_in_stream(f, visual_features=features)\n",
        "\n",
        "# Draw all generic \"objects\"\n",
        "if analysis.objects:\n",
        "    objs = []\n",
        "    for obj in analysis.objects:\n",
        "        r = obj.rectangle\n",
        "        tlx, tly, bw, bh = r.x, r.y, r.w, r.h\n",
        "        objs.append((obj.object_property, tlx, tly, tlx+bw, tly+bh))\n",
        "    draw_detections(img, objs, colours=[(255, 0, 0)]*len(objs))\n",
        "    annotate_class(img, objs, colours=[(255, 0, 0)]*len(objs))\n",
        "\n",
        "if analysis.faces:\n",
        "    annotate_faces(img, analysis.faces, lambda face: f'Person aged {face.age}')\n",
        "\n",
        "display_image(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4505133-28c7-46a6-8398-16df22bb1b91",
      "metadata": {
        "id": "b4505133-28c7-46a6-8398-16df22bb1b91"
      },
      "source": [
        "**Question**: How many objects were detected (red bounding boxes)?\n",
        "    \n",
        "<details>\n",
        "<summary style='cursor:pointer;'><u>Answer</u></summary>\n",
        "\n",
        "There were 3 objects detected. All of them \"Person\" objects.\n",
        "</details>\n",
        "<br />\n",
        "\n",
        "**Question**: What form were the bounding boxes returned from the server?\n",
        "    \n",
        "<details>\n",
        "<summary style='cursor:pointer;'><u>Answer</u></summary>\n",
        "\n",
        "The bounding boxes were returned in `tlx`,`tly`,`bw`,`bh` form as pixels. We convert these to `tlx`,`tly`,`brx`,`bry` form for compatibility with our previous lab's functions.\n",
        "</details>\n",
        "<br />\n",
        "\n",
        "**Question**: How accurate do you think the age predictions are?\n",
        "    \n",
        "<details>\n",
        "<summary style='cursor:pointer;'><u>Answer</u></summary>\n",
        "\n",
        "You shouldn't guess someone's age. That's rude.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd4d4343-d4b1-46d1-b6b8-bb3cf262ac76",
      "metadata": {
        "id": "cd4d4343-d4b1-46d1-b6b8-bb3cf262ac76"
      },
      "source": [
        "## 3.3 Optical Character Recognition (OCR)\n",
        "\n",
        "Another common and useful task is detecting text in images, and storing the strings of that string in the image. Using Azure's Cognitive Services, we can detect where text is in the image, and what it says. The text is detected in regions, and each region is processed to produce a single string. As always, we don't have to do anything; Azure handles all the computer vision for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb037a99-bd7b-4194-97bc-3b9dc1e63e29",
      "metadata": {
        "id": "eb037a99-bd7b-4194-97bc-3b9dc1e63e29"
      },
      "outputs": [],
      "source": [
        "# Send image to OCR endpoint\n",
        "image_fpath = Path('ocr', 'advert.jpg')\n",
        "service = cog_client.recognize_printed_text_in_stream\n",
        "img, results = load_and_detect(image_fpath, service)\n",
        "\n",
        "# Extract results\n",
        "region_boxes = []\n",
        "for i, region in enumerate(results.regions):\n",
        "    for line in region.lines:\n",
        "        # Get bounding box\n",
        "        tlx, tly, bw, bh = [int(v) for v in line.bounding_box.split(',')]\n",
        "        region_boxes.append((None, tlx, tly, tlx+bw, tly+bh))\n",
        "\n",
        "        # Print detected words\n",
        "        words = [word.text for word in line.words]\n",
        "        print(f'Region {i}: ', ' '.join(words))\n",
        "\n",
        "# Draw on and display image\n",
        "draw_detections(img, region_boxes)\n",
        "display_image(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca249d8f-423c-41cf-b6bd-be4a6cc43bf8",
      "metadata": {
        "id": "ca249d8f-423c-41cf-b6bd-be4a6cc43bf8"
      },
      "source": [
        "**Question**: How many regions of text were detected?\n",
        "    \n",
        "<details>\n",
        "<summary style='cursor:pointer;'><u>Answer</u></summary>\n",
        "\n",
        "There were 2 regions of text detected.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bca00e7b-619e-4418-becb-709dc812e44f",
      "metadata": {
        "id": "bca00e7b-619e-4418-becb-709dc812e44f"
      },
      "source": [
        "### 3.3.1 Asynchronous OCR\n",
        "\n",
        "You can obtain OCR asynchronously, receiving the regions of text as they become available, instead of waiting for the models on the server to finish processing. This is called the \"Read API\". Although in this case it only takes a few seconds, larger models or larger images with more text may take longer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f72eb40-f24c-4e38-8772-e6b5cd5c79b0",
      "metadata": {
        "id": "6f72eb40-f24c-4e38-8772-e6b5cd5c79b0"
      },
      "outputs": [],
      "source": [
        "# Load image and start async operation\n",
        "image_fpath = Path('ocr', 'letter.jpg')\n",
        "img = load_image_rgb(str(image_fpath))\n",
        "with open(image_fpath, 'rb') as f:\n",
        "    op = cog_client.read_in_stream(f, raw=True)\n",
        "\n",
        "# Wait for the async operation to complete\n",
        "op_id = op.headers['Operation-Location'].split('/')[-1]\n",
        "while True:\n",
        "    op_result = cog_client.get_read_result(op_id)\n",
        "    if op_result.status not in [OperationStatusCodes.running]:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "# If it was successful print the results as before\n",
        "if op_result.status == OperationStatusCodes.succeeded:\n",
        "    for result in op_result.analyze_result.read_results:\n",
        "        for line in result.lines:\n",
        "            print(line.text)\n",
        "\n",
        "# Display image\n",
        "display_image(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "417032e1-7081-4fe5-8433-afe5ae2dda68",
      "metadata": {
        "id": "417032e1-7081-4fe5-8433-afe5ae2dda68"
      },
      "source": [
        "**Question**: What is the name of the technique used to interact with the server in the section that uses a `while True:`?\n",
        "    \n",
        "<details>\n",
        "<summary style='cursor:pointer;'><u>Answer</u></summary>\n",
        "\n",
        "This is a general computing question. When the server responds immediately with an operation id which you can repeatedly query the server with, it is called \"polling\".\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1bd99a9-9f55-4ba3-a066-7223ae35d409",
      "metadata": {
        "id": "f1bd99a9-9f55-4ba3-a066-7223ae35d409"
      },
      "source": [
        "# 4. Detecting Faces\n",
        "\n",
        "In earlier labs we showed a method for detecting and identifying faces. Azure provides tools to perform these tasks on their cloud infrastructure, but access to these are now restricted under a \"Limited Access\" scheme."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46339b87-a4c2-4ab4-b2a8-431a7fd2184e",
      "metadata": {
        "id": "46339b87-a4c2-4ab4-b2a8-431a7fd2184e"
      },
      "source": [
        "## 4.1 Ethical considerations\n",
        "\n",
        "With the recent development of AI, especially in computer vision techniques, we must always strive to create technology that is used fairly and respectfully.\n",
        "\n",
        "Some platforms, including Microsoft Azure, provide an endpoint to predict the emotions of each person just looking at their face."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75cc8fa5-3fe4-4949-844d-ec0d769defc8",
      "metadata": {
        "id": "75cc8fa5-3fe4-4949-844d-ec0d769defc8"
      },
      "source": [
        "We need to be very careful with a technology that has such potential to be misused in real-world scenarios.\n",
        "\n",
        "Humans use facial expressions to communicate with others. That is, if someone is smiling, that person is telling others that they are happy. However, even within this simple rule there is nuance. A well known example is the contrast between Americans and Russians when it comes to smiling. Americans are known for smiling as a show of goodwill. If you do not smile in the US, generally you are communicating that there is something wrong. In contrast, Russians generally reserve smiling for when there is actually something worth smiling about. And that's just between cultures, there's a lot of variation between individuals (e.g. temperament, neurodiversity) and contexts too.\n",
        "\n",
        "In [Emotional Expressions Reconsidered: Challenges to Inferring Emotion From Human Facial Movements](https://journals.sagepub.com/doi/10.1177/1529100619832930), Barrett et al. argue that all available evidence suggests that evaluating a person's emotions from their facial expression has: limited reliability, lack of specificity (recall) and limited generalisability. That is, determining emotion from facial expression - whether by human or machine - is not known to be accurate or reliable.\n",
        "\n",
        "> \\[Scientific\\] frameworks propose that expressions of the same emotion category, such as anger, vary substantially across different people and situations. For example, when the goal of being angry is to overcome an obstacle, it may be more useful to scowl during some instances of anger, smile or laugh, or even stoically widen oneâ€™s eyes, depending on the temporospatial context.\n",
        "\n",
        "So, the technology has fundamental limitations. What are the ethical problems with that? Here we present just two salient issues (although many more exist). The first is a privacy issue: many people do not want their emotional state to be evaluated without their permission, even if it is done anonymously and incorrectly. The second is an issue of fairness: if you do not conform to the algorithms idea of \"positive\" emotions, you are going to be unfairly targeted. So, consider two unethical uses of this technology currently underway:\n",
        "\n",
        " 1. [*Monitoring shoppers in shopping centres*](https://www.theguardian.com/technology/2019/feb/24/are-you-being-scanned-how-facial-recognition-technology-follows-you-even-as-you-shop): Shopping centres are monitoring your emotions as you interact with advertisements using cameras attached to billboards. This is being done without anyone's consent in the name of improving their advertisements.\n",
        " 2. [*Monitoring employees while they work*](https://www.insider.com/ai-emotion-recognition-system-tracks-how-happy-chinas-workers-are-2021-6): Some workplaces have started implementing cameras that monitor their employee's emotions and organising interventions if the workers show signs of negative emotions. This is being done to prevent violence, trouble-making and provide emotional support to workers.\n",
        "\n",
        "**Question**: What is unethical about each case?\n",
        "\n",
        "<details>\n",
        "<summary style='cursor:pointer;'><u>Answer</u></summary>\n",
        "\n",
        "In the first case, it is unethical to collect data about people without their permission. Since the individuals are not identified, there is no issue of fairness, since they won't be treated differently.\n",
        "\n",
        "In the second case, there are a myriad of problems, just from the article, we can list at least 3 different ethical problems:\n",
        " 1. Breaching your right to privacy at work.\n",
        " 2. Stripping people of their right to freedom of expression by enforcing an algorithmic understanding of \"positive\" emotions.\n",
        " 3. Creating perverse incentives to game the system.\n",
        "</details>\n",
        "<br />\n",
        "\n",
        "**Question**: More generally, how can you tell if something is unethical?\n",
        "\n",
        "<details>\n",
        "<summary style='cursor:pointer;'><u>Answer</u></summary>\n",
        "\n",
        "In an ethical world people's rights are worth more than the money gained by denying those rights. It is important to look at the real world impact of a technology to make the most informed decision you can.\n",
        "</details>\n",
        "<br />\n",
        "\n",
        "**In your own time**:\n",
        "* Here is a brief summary of this area in 2019 https://partnershiponai.org/paper/the-ethics-of-ai-and-emotional-intelligence/\n",
        "* Here is a specific, itemised list of ways to help identify ethical issues in AI usage https://t-guider.com/index.php/2021/04/06/identify-guiding-principles-for-responsible-ai/\n",
        "\n",
        "**Remember**: Just because you can get a number out of your algorithm, doesn't mean that number is accurate or useful."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f7947a4-3e2b-4fcc-a781-4c34f4e80073",
      "metadata": {
        "id": "2f7947a4-3e2b-4fcc-a781-4c34f4e80073"
      },
      "source": [
        "# 5. Receipts Recognizer\n",
        "\n",
        "Consider the following image:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![receipt.jpg](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAlgCWAAD/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAILAUsDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD9U6KKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOH+OXji/8Ahn8GfHHi7S4refUtD0W71G2ivFZoXkiiZ1DhWUlSVGcEHHcV59+xf+0Vf/tKfBmHX9fsbXSPF9jdy2Gs6bZo6RQTDDxlFdmYK0TxsMsep54rf/a3/wCTW/i1/wBitqX/AKTPXzn+z7M/wV+MHwpvJHMfhv4weBtNglODtXXLGzjKMT0BltiV9WaOqpe9Kaf91L1fO/xUbebaCrpCDX95v0XIvw5r+STPoL4PfGTWviD8ZvjR4R1G1sIdN8F6lYWeny2sbrNKk9oJnMxZyGIY4G0Lx1B617JXzD+zKpX9qT9qbIIzrmjkZH/UOWszwj4o+Lv7U+q+LNf8GfESL4V+A9I1a60TRvsuhW2pXWqyW7bJbqZrjKrF5gZVSMKSAcsMcz0glu4Rb/8AAY3f3tfeTH7bb+3JL/wKVl9y/A+saK8I/Z3+M3iXxrZfEDwl42Syj+IHgPUDp2oXOmxmO3voni821u0jYnZ5iHlMnBU9jgeH/sm+Nf2i/wBprwP4M8dy/ELTvC/hqxuvs17azaBb3Fz4kEc5FzIzgKtsoGYk8sAkozN1FNLmdltZO/lLZ/8AA3123s3pG77tfNdPz8tNz6l8E/GbTfHXxU+IPgeysbqG78FmxjvLqbaI5pLmJpVEYBJwqhck45JGMDJ5/wCCnxi1r4kfE34x+HdTtbGCy8G65BplhJaRusksT2ySkylnYFtzEZUKMdu9eC/sxeBPFVn+2T8fnufiVrGoJpl7ox1CObTtPUauHsWKCYpbgx+WCAPJ2Zx826sj4U6b8TvGH7Un7SXh7wT4mtfAOixeIbS81DxH/Z0eoXjytaRrHbwRS/ulGEdndw55QBRkmlH4o+cL/O8Nfxdvu3Cp7rdnopJfLllp33t/w17fedFfIPhX4r/FebwT+0Z4EvfEtvq3xE+HVt5mkeLLXTIYGvBNZtc25ltyGiEgKlThdpBHHc73xe+Pnii8/ZD8GeKfAN/DZ+PfHa6NYaJcyRRyJHeXhjLsUdWUhU84kFSBt6cVMnyq61+D589+X8ikrtJ6fF8uW12/LW/ofUFcJqWr+PovjPoum2WiWM3w3l0i4m1DWHcfaob8SKIYlXzQSjIXJPltyB8w6HxPXP2jfEVx+wXp/wAR9Lulh8eappNpp9vN5EZ2axNMloT5bKU+W4ZjtK4+XGMcV1OqfEbxXo/7X3gHwA+sGbw9feDL3Ub+3NtCDcXkU0SLNvCbl4ZvlUheenSrlHlqqF9m15NqMm/uSv6uPS5HNenzWtdJ+a96K/Fu3opdT36ivjSbx18cvib+2F8W/hl4U8bWXhPwX4fttKuv7Um0aC8urAy2yuYrdWAVmlYuxabzAgj+VecV3/7OvxB8fWvxk+JPwl+IHiC28aXfhm3sNT07xJFYR2M1zbXQk/dzwx/uw6MmAUABHJ9KUfeUX/Mrrz6/o/ubXQua5G12tfyulb80tOrPoyvHfgT8Yta+J/jb4v6PqtrY29t4P8THRbBrON1eWEQRybpSzsC+XPKhRjHFeW+E/FHxi/aZ8VeONe8F/ES1+G3gfw7rVxoGj2i6Bb6i+rzWxCzXFw8p3LEZNyqsRRiM8gjJz/8AgnrrWveINc/aBvfFOn2+l+Iz46ki1C1s2ZoFnjtoo3MZbnYSpZc84I5PWpheUr9HC/3uFn9z/HUU/dVl0lb7lK6+9fgfVXjT/hIv+ER1j/hEv7M/4Sf7LJ/Zn9teZ9i+0bT5fneX8/l7sZ2846V8X/Ef41fth/C/xd4C8O6ra/A+4vfGepPpenyWcesNHFKsZkLTFnUquB1UMc9q+6q+Vf2vv+S9fst/9jjP/wCkrUnpOHnKK+Tkk/wYSf7ub7Rk/ui2vyPUfgb/AML08/V/+Fx/8K98nbF/Zv8Awg327duy3med9p7Y2bdv+1ntXrNfLv7Yfxo+Inwu+IXwa0T4emC4vfFmoahpkmn3cKNBPKbYC3klcqXSOKRxK/lkEqjDnpS6sn7Q3wp+HsGkS+K7b4o+NvEniC206y12Pwytva+H7SRczXFxDAcOke1tpYjJZdxPIq+bnV0utvV3St+Kd3pbqNx5WrvdX9Fr/wDIvRXZ9Q0V8x6B4o+JnwV/aC8CeBvG3j1fiV4f8dWt+tpfXOi2+n3Wn3lpEsxUfZwqPG8ZfhhuBXrjOYda8ZfFD47/AB68beDPh942i+G3hPwIttbajrEWj2+o3epahPEZTCgnyiRRoU3ELuLHGcHIO1tb3f3Ozv8AP813Ftfm02+d+34/c+zPQPB/xi1rxB+1B8Q/hxcWtimh+HdG0zUbW4ijcXLyXBl8wSMXKlRsGMKD1yTXsVfFP7KeoeMbn9tj46WXjsWMviLS9E0axkv9OiaKDUI1MzRXKxknyy6OpZNzBWDAHFdP4R1z4wftQSeJvFfg/wCJkHwx8G2WrXekaFZ23h+21KXUBbSGJ7q5efOFaRXAjj2naOWzUQ+CHW6k7+XO0n9zStv3WjHLScr6WcV83BP/ADd9vPVH1fRXyfa/tLeLvEH7G3xZ8VTNaaH8TPAkesaRfzWEQkt49Rs1bE0aShhtYGNwrg43Ec1V+Eviz46+IvCdh8bPE3i6xtvAraDNqifD230WI3NzAtqzwzPecMk0jBXKKNihtoqpSUVKT+GKTv0s02vPVLt+thJtqKWrbVvNNJrtu/T8L/XVFfGXhPWv2jPGPwV0X40eHPiJpHie+1Kxj1mP4bwaDbpp80LgMbOO7DfaBMoyN7ORvGCuOa+wdHvZdS0myu57SXT57iBJZLSYgyQMyglGxxlScHHHFaSi4tqWjWjX9fpf8iFJSs1qns/6/W35lyiiioKCiiigAooooAKKKKACiiigAooooAKKKKAPJf2t/wDk1v4tf9itqX/pM9eN/ED4d6l46/YD8A6j4dG3xh4R0DR/FGhSKu5hd2lvHJsA770EkeO++vpz4ieB7D4meAfEXhHVJbiDTdcsJ9OuZbNlWZI5UKMULKwDAMcZBGexo+H3gew+G/gHw74Q02W4udM0PToNMt5LxlaZ4oY1jUuVVQWIUZwAM9hS1UJ8rtJuDT7OPM7/ACbRd1eF1dLmuu6ly6fNJnzH+xH8RNM+L3xa+PHjLR3D6drkvh+9iGclN+lqWQ/7StlT7qa3/wDgnW62f7Pd1oUrBdU0HxPrWnahb5+aGcX0r7T/AMBkQ/Qiu6/Z3/ZT8Gfsx3XjKTwdPqjQ+KNQGoXNrfyxPFbMC+2OAJGhVAJCAGLHAHNZ/jT9kPw74k8aaz4q8P8Ai/xr8NtX1zB1hvBmsC0i1FwoUSSxyRyKJAox5iBW5POTmrlJcycVpypW7Ncv4KzX4mUU1Dkk/tXv3XvL73e/4HDfAVhrX7VH7VuvWbCbSjPo2krMpypubawYToPdS6g+hrW/4JuqqfsX/DoKoUGO8PA7m9n5r2H4W/Bzwv8ABzwOPCnhezktNOZ5ZriaaZprm6nlOZZ5pXJaSRjyWPsBgAAN+Cfwh0f4D/DHRfAugXN9eaRpKyLBNqUiPO2+V5DuZERTy5xhRxiqTUYuPlBf+App/mVJub5n3f3WSXzstfM8X/Z1/wCTwv2o/wDr70D/ANIDUv7Kn/Je/wBp7/sbbT/0giru9a/Zj0LUPjV/ws/TPEvinwtrtx9lGq2eh6isNlrK25/crdxNGxcBfk+VlypI7103w/8Ag7o3w38XeO/EWmXN/Pe+MtRj1O/ju5EaOKVIViAiCopC7VBwxY579qzjvFvpDl+5ws/mov0FUXNLT+ZS/wDJZJ/c2eK/s+28d1+11+1RBKoeKS50FHU9CDp7AivGP2YZ5PE/jr4P/CeZ2mPwnv8AxNd6jG38Jtrh7Kwz/wAAumI/3Pavs/wX8GtF8C/Enx742sLq/m1XxnJZy6hDcyI0ERtofKj8kBAygqcnczc9MdKx/hz+zb4S+F/xc+IPxG0dr59e8bPDJqEdzJG0EBjB4gVUDKHJ3NuZskDGOlVB2nBvZRSf+KKSj9zux1PejO27l/5K9JL5o+R9LJl+L2i/AAthNJ+Lt34k+zA/8wtbY6rFkf3fPuFX6qK9x8Y/8pEvhz/2IWq/+lUNejw/s3eE7f8AaMuPjUj3/wDwls+jDRHg8yP7J5YYHzduzf5uFC5342/w55ra1L4O6Nqnxn0X4my3N+uvaTpFxosFukiC1aGaRZGZlKbi4KDBDAYzwazinFUl/Le/r7N00/mlFvzbHU972j72t/4Hzv7m2vRI8W+Av/J8n7UX/XHwx/6Qy1Y+Gf8Ayf8A/Gv/ALFbQf5z1694R+DOieDPit49+IFldX8us+M1sE1CC4kQ28QtImii8lQgZcqx3bmbJ6Y6U/Q/g7o3h/4weKPiPb3N++ueIrC0066t5ZENskdvv8sxqEDBjvOcsR0wBTfxUn/KrP8A8AlH82VUfNz268v4cl//AElnjf8AwT1lS2+DPiXRXYDUtF8aa7Y30PeKX7Y8mCPdXU/jVT9inWbPXviP+0teWEqz2zfEGeISKcgslvEjY/4EprtPGH7IPhvxF481nxZovi3xr4Av9d2nW7fwhrP2K31RlAUSSoY32ybRjfGUbk85Oa6T4Ffs4+D/ANnWHxNbeDUvLax17UBqMtncSq8du4iSLbEQobbhASXLMWJJY5qaUVHlv0go/Ncn/wAjp/V5qa3t1m5fJ83/AMkepV8q/tff8l6/Zb/7HGf/ANJWr6qrz/4j/BXQ/ih4u8BeItVutQt73wZqT6pp8dnIixyytGYyswZGLLg9FKnPem170H2lF/JSTf4IT1hOPeMl98WkeP8A7TChv2qv2W8gH/ic6weR/wBQ812H7UHxS8VeCV8BeFfBM1jp3ibxxrq6Jb6zqUPnw6bGIpJZZxFkea4WMhEJCliM8cHtPHHwb0Xx/wDEDwF4v1C6v4dS8F3NzdafFayIsMrTwmFxMGQlgFORtK89c9Kb8Z/gn4b+O3hSHQ/EYvIPst1HqFhqWl3LW17p91Hny7iCVeUdcnBwRzyDSStFL+9d+l1f70mjST5mmv5bfO8rfddHy94w+GcXw5/bM/ZuOp+N/EnjjxVqVzrstxea/fBkSNNNYYhtYlSGBNzfwRgnuzYr0D9k+VNO+O37TeiTsE1KPxfBqRhPX7PcWURif6HY35VuaF+xV4T0jxr4a8a3nirxl4i8b6DfC7g8Sa5qiXV3LF5UkZs2zF5aW5WVyUiRCSQS2RW98UP2W/D/AMR/HUPjWx8R+KfAPi4WosLnWPB+oraS3tsCSsU6vHIkgUkkEruHHPAxps4vylH72pJr7rP5vyecvf07W+bXMnf5S0+S7285+EesWesf8FA/j3FaTLK1l4e0K1n2nIWQLKxX6gOteWfsV/s26d46+EOovefEH4jaDq2meJNX02/0vw94vu7C0tpo7yQ7VgjYKpKsrHjktnvX038Gf2VfBnwK8a+IfFHhqfV5NT16zt7XUG1K8Fybh4mdzcO7L5jzSNIxdnc54wFAxWV42/Y/8OeJvGGteJNC8YeNvhxf66d+sx+C9ZFlBqUmAvmyxvG6rJtGPMj2MeTnJJrKEfZqK30kvm581/Tfz18ipS5ubom4v5KHL9/+R4vq2g/D3w7+xL+0zZ/Dy817U7aOTXotX1DxBdPdT3WpJbrHcSCZiTIp2r8xPJ3d6+lPhbrmleE/2bfB+r6xcRWOjaf4Usrm7nkX93FClojOzADoFBJ4qJf2b/BVn8A9S+EGlWtzonhG/wBOuNOl+xzZudswbzZfMkD7pGLMxZg3J6dq7XQfB2naD4J07woEN9pFlp0emBL0LIZoUiEeJOArZUc8AHJ4rWTfLNLVtQSv/dUl8lqrLtoZ2vUhJ7Jzv395xa+eju+58q+JPgXdfCXwjf8Axb/Zq8XnQtMms28QS+C71zceG9XhMZmZoomIa1kdcENGQOFXCjJH0r8HPiND8XfhT4S8awWj2EWv6Zb6iLWQ7jCZEDFM4GcEkZxzjNeND9gvwbFpk3h628bfEOz+H8rMH8C2/iJl0nym+9APk88RHnMYmA5PrX0Vo+j2Xh/SbLS9MtYrHTrKFLe2tYECRwxooVUUDoAAAB7U1bla6aWXVLW+v3WWytpa43dyT663ffa363fn1sXKKKKkYUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUV538Z/jz4S+A+i29/4mmvpJ7sS/YtM0qxlvLy8aNN7iOKNT91eSzbVXuwql8CP2ivDH7QXwhh+JGg2+paZ4fka4BTVoUS4QQsyuSsbyDHykjDE4/Kp5l7zv8O/kOzVvPbzPUaK+S9S/wCCl3ww8O+INItPEHhvx94Y8P6xJ5en+Ldc8NyWmlXYwDvjd2EjLgg5EfAOTgc16h8aP2otA+DOqWOk/wDCL+MvHWuXdr9vTS/BWhyalMltuKiZyCqKpKkctnjpVPRJvrp89/yEtXZev6fnoeyUV5L+zn+094I/ag8MX2seDZr2KTTrj7LqGl6pb/Z7yylIJCyJkjkA4Ksw4IzkEDP/AGn/ANrLwj+yfoWg6n4r03XNWXWrxrG0tdAtop5i4TcSRJLGMdBwSckcdaU2qfxabfjt99wj7/w+f4bntVFcX8H/AIueHfjh8M9E8d+GZ5JNC1aAzRG5UJLHtYq6SAEgMrKykAkZHUjmvHfgX+3/APDX9ob4v6j8PPCll4g/tG0guLqPUr20ijsbuKGQRs8LrKzkEnI3IuQDnB4q3Fqbpv4lfT03EmnD2i20/HY+lqKK8n8dftJ+GPh/8cPA/wALNRsNZn8Q+L4pZbC5tLRXtIxGGJ81y4YH5T91WxwWwDmp3ko9XsPo5dFuesUUUUAFFeFfGz9sTwb8E/Gll4MfRvFHjjxtdW/2xfDfgvSW1G9jt8kea67lULweN2e+MHNbGl/tTeA7r4K3/wAU9Wn1Twt4X02VrfUl1zTJ4bywmEixGKWBVZ9wd1Hyhhz1pKSacr6L/O356eug7PmUer/4f8tT12is3w34i0/xd4e0zXNJuPtelalbR3lpcbGTzIZFDo21gGGVIOCAeea0qppxbTWpKakrrYKKKKQworh/i58a/BfwJ8O2mu+OtaGhaVdXsenQ3Btpp99xIGKJtiRm5CMckYGOTXbqwZQRyDyKOl/6/rVA9NGLRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAcl8XAP+FVeMzjn+xL3/wBEPXzP/wAEmf8Akynwx/2ENQ/9KXr2/wDaG+F/jv4seFYdF8E/Ez/hWol82LUpv7Bg1X7bbyRlDFtlZfL6k7lOea8m/Zg/Y6+IX7NfhW/8JwfHBta8JNp93Dp+lp4Vt7VrC8mYMLsTec8jlDuPlsdp3dsCs6d4zrTa3ikvNpuX47Lz3stSqlpRpRvtJt/NW/4Pp56Hif7fGrP+2N8ZfCH7NngOA393o+pLq/ijXFXMGkxhChQt3YJKxI/vGNByWA+wPjJp/wAY9L8M6HYfBRvBC3FujQXjeNvtZAjVFWIw/Z/48g538dPevmv4P/8ABPP4u/AZNa/4Qf8AaYXR5taufteo3UvgCzu7i6l5+aSaed5DyWON2MsxxliT7p8RPgT8VfET6NqPhP4/ax4N16DTINP1ORtBtL+wv5I9xa5WzkwsErsxyUbGAo/hFXyqNJRT1bu/N2/JWt31v1dlfmqcz2SsvS/5u9+2lvX5+/4JeX9n4f8AEnxo8GeItMvrD4w2+ttf+KZ5po5ba7ZnkCtb+WqhFDM52nP+sBDEHaur/wAFMI0m8Z/szRyKHRvH9srKwyCC8WRXuH7Mf7Juk/s5z+KNbm8Q6j408ceKrgXOt+JNUVUkuGBYhUjXIjTLMcZJyeuAoE37Sn7Mq/tD618MtQPiM6AfBXiGLXRH9h+0/bNjKfKz5ieXnZ975sZ6Gql73sea3uune23uuN7LtZbfd2Jjp7W2z57d9U7X87s+DrX43XH7Hfwy/ab+B0dw0Wuabq23wZbhsSvb6lhVEQ6kxoyycfxMa7H9mr4VwfAn/goB4P8ABQEcT6P8KI0u3XhWuGkEk7/jIzn8a+jfjR+wZ4f+M/7UXgj4x3uuNZN4fFubvRFsRIuovbyNJCxl8wbMEqCNjblQDiuun/Zdiuv2tJ/jXL4i3xzeGj4dfw/9ixkFsmXz/M9ONuz/AIFUQ5lCDfxap+kYSjB/Ny19fIdVKU5JfDo/nKcZS+62n6n56fHr4/ajb+H/ABT46+Hvxb+Pni/W9I1AKvibT7BLXwNGwnUGF4gAoAVgoLBg7Fcghq+jfG3xo8Y61+0x+x08ev6jpmn+LdDlv9Y0mxu5IrO8ke1V/wB5ECFcBicbgcdqluv+CY2tL8OPEHwx0347a3p3wqvp5Lyz8MDQ7d2t5y4dDLc7xJNGrgMYxsBIByDzXrd1+xqt18RfgJ4qPi4r/wAKr0o6YLT+zf8AkJ/uFi37/N/c/dzjD9cZ71dG0PZ32Uov5cslL8bd76Pvaa15c9t2pL8Y8v4X6K2q7HgHgbRfiF+0V+1J+0j4Il+M3jbwf4V8P6jDLaW3h/UDHOkjqwjWOZ9xhhXYxaKLbvLDJGK9i/4Jm/GLxV8Zf2axeeMdUl1zWdH1e50j+07g5muY4xGyNIf4mAk27jydoJJOSe/+Df7Ma/CX43fFz4h/8JIdVPj+5guP7O+w+T9g8sP8vmeY3m539dq4x3o/ZA/ZjH7KPwz1DwiPEh8Ufa9Xn1T7YbH7Js8xUXy9nmSZxs+9nnPQUsP7lJRnv7OK/wC3k1f8L67F1rSnKUf57r/C07/+TW0PE/2mP2c/jN4R/aKk/aC+BFzpWsa9NpS6bq3hfWAB9riXaMRsSoIISMkb42Bj4Zt22vIv2jfjxF+2Z/wTv8beL549c8D6/wCDtUhtNW8P2d6Vtbm48+BNk4K5lixKHCHBWRBknbk/W3xS/Z9+LHiTxvq2teA/2hda8BaXquw3GiXGhWurQQlY1jP2ZpWVoAQu4hc/MWbvVHw5+wj4H8N/sy+KPg3HqGp3dr4mZ7rVdeunV7y4vWZGFweNvytGmF9F5JJLHBxboyh21S635r6Pa2+/V9DaMlGvCb7q/pa337bdEfPnxC8O67+z5/wTAvfEPhv4j+ObnWNS0zQ9RhvNR1x3l0vzGtg0Fm6BGhh2sRsBPBxmrHxW8cfET9ln9jW7+LEnxI8R+L/iF46t9LjU6pMkum6NLOjSFrK1KhY8RkrzncyqxHUV63efsTeLPEn7KOt/BTxT8YpvEUNyLO30vWJfDsMP9m2ts8TJD5SSgzZ8vG95M8j059T+JH7Mvhv4tfs723wj8TXFxcaXBp9pZpqFqBFPHLboojnQHcA2Uzg5GCRzmuqvLndaUOsotf4ftLyey9evU5qC5FSjLopX/wAWnK/S936brofDXwj8e/F/wn8avhnL4XsP2j/EOkapfxWXi+H4q6I7aYsMpVTcWzKW+zqhZn5PAUZYjIOH4w/aD8c/HT4zfFdJrv4+W2keGNWm0bQLL4L6eJLS3eFnQvfuGBkZ2QNsPYkBgMCvs74U/s0/FbwXr2gt4q/aK17xh4X0NkNpoUOh2unNMEXaiXNyjPJOmMZDEbiMk1h69+xL4l8O/FTxX43+Dnxj1D4US+LZxda5ph0K21a1nmySZI1mZfLJLOxPzHLnBA4EztJpdPet3V+W33e9te1/ucLxT7+787Xv+m9r2+/4v/ay/wCFjfEz9h/4TeL/AIqzeLPD3jSy8ULod1pN6j6fFdofOMd7NasgP2gLGAsnAw0mB83H6k/B34a/8Kn8D2vh7/hKvE3jLy5Hm/tXxbqP26+bec7Wl2rlV6AY4FeU/Fz9jmL4z/s323ww8R+PNc1TV7W8GqQ+L9QVJrsXnmSPvMY2r5YErosaldqbQDxmvV/g/wCEfFfgfwPaaT4z8byfELXoncy65JpkOnmRSfkQQxEqAowM5JPJJrTmVpxWmt/JpqP3apvp+hMldwfZW9NZW/Bpf1c7WiiisiwooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA+fv2qP2nta/Z81b4e6N4c8Af8LB17xnqEum2Vh/bKaZiVVQgeY8br8xfHzFQMda6P4MfE74peMo9ek+I3wd/4VfHYxJJZN/wk9rq/wBuJ371xAo8vbtXluu/jpXN/tU/sw65+0HrHw81nw34+Hw/1zwZqEupWd//AGOmpZlZUCny3kRflKfxBgc9K8n/AGYfjv8AFV/2ofiR+z58T9f0/wAc3OiaZ/aFp4qsdOjs5CrCEhJYogEGVuF4xlWVhuYEERDmkpwXx+816JJ6ee+5crLll9lWv3u5Nfda2xN8I/23vjX8cvDNp4n8G/sx/wBreGLm5kt01L/hP7KHmOQpIfLlhV+CD25xxXon7R/7Vnif4N/FTwF8PfB/wx/4WN4l8XW11cW1t/b8Wl7PIXc67pYmQ/KGOSy/dwMk18ufET4d/HH/AIJq/Aa38ReEPjJpfirwbo+pqZ/CepeF4LZH+0TfNtnEjzOd7AlQ6YGSDxivoT4qfs++Kf2nNe+EPxl8G/ENvhX4i0jRHntRLoMeqMhvIVLArLIqDCMy8q3XIwa10lyuO0XaXe7g2vK1+2ttyJe7KUXu03HtpK3rtvf5HsvwQ8dfETx1pOpXHxE+F/8Awq++gnWO1s/+Egt9X+1RlcmTfAoCYPG08967Hxl4nTwZ4X1LW5NO1LV0sYTL9h0e1a6u5z0CRRLyzEnp+ZA5r41/Ze/a0+JEevfG/wAEfE21n+JGt/DNwyaj4O0tTe6qpkdDGtum1DJ8oIVdv8QOdua+jPgb8f8A/heDawv/AArf4g+AP7NERz450L+zRdb9/wDqP3jb9uz5umNy+tL+JFOD0aTXo+uvn/VhL3G1PdOz9e2nr/TOD/Z1/bCvfjt8afiD8PNR+Hl74HvPCUMMztqOpRT3EokI2rJFGpSNsEEgSv1xUXx+/aq+IXwhk8S3vh/4Ca74v8KeGUMmqeIbnWLfTYdgjWR5LaJlkluEVWwWVQAVYfwk15N+yl/yki/ah/642f8AKOut/wCCg37QV5onhuD4H+ArA+I/il8RLeTTYNPhIP2OzlBSWeT+7ld4UnAADuThMHHmlKhRnBe9OO3eTb/rS3c0hb29WE/hjLfsklf+nfsejeEP2trX4ofs86X8UPAHgjxB4wuNSuPsMPhuzESXMdwHKMJpGbZHGpXJkJIwynHOK5T4U/ttat4g+P8Ab/Bv4mfCu/8Ahb401Cza+0yM6vBqtvdRqjucyxKoU7Y5MY3DKMCQeD1PwL/Zp1f4E/sp2Hwy8LeLF8P+LEtXkfxMlil6sF9K++SRYJCFkUElFDY+UAnmvlHTNK8Xfs3/APBRTwFJ8VdctfjJrHjiwOm6T4pNqdPutJwWQhLSNzCiEtg4GSHZgQdwbq936z7JbPRevK9F81e76eZz3l9XdR7rX5XWr+T2Wtz9Lq+Tf2zP2+rP9k/WLDSLHwZN461Q2f8AaWpxRaj9jj022aVYYXkfypMmSQlQuB93Oa621/bGgm8aah4fufg58W9JtrFrsS+IdS8L+TpO23SRzJ9o80/I4jOxsfNuXpmvy0+KX7RXgD4pfs2/FnXNX8SrcfGf4geI7W8bRBZXJ+wabbTBbe2E5iERCxgscPzlc/MDXHKbdnDbR+qbsv1fpFnUopJ82+34N/pb1aP1D/aO/aw1n4Kx/C618N/D0+PNd8fXJtLHTDrSad5cnlxuq+Y8Tqc+ZjJ2gY612nwO+I/xR8dzawvxH+D/APwqyK1WI2Un/CT2ur/bCxbeMQKPL24X73Xdx0rxfxd8JYv22Phv8E/H3wy+Jw8JnwrI95p2s/2AbzfOgWFv3M7RY2SQsPmUg+mME8P8If2gPi9a/Gb42fAX4h69ZeO9U8P+GrnVNO8Uabp6WczEwxsiSRRAICRcJgAZVlI3MCMdFZ+xdaNtY87S/uxSennvuY0k6sab6NRTfXmcmtfLZaeZ6DB+3F4s+JHiPX4fgr8EdU+KnhfQbxtPvvEh1610qCSZfvrbLMpM4AIPBB5HGCCfSvi98WvjH4P1fS4PAXwIb4i6dc2KXFzev4us9Ka1nLMGtzHMpLFQFO8HHzY7V+en7OWpfG34Y/8ABP4fFHwH8UtG0Pw94buLq4fwlJ4chuDfYusSefdyEurndwqKPlCjcCcj7w8UftVx+Ff2J7f43araR2N/d+HLfUIbAE7GvZ41EUS55KmVx77eamrajTbbu48t+7unbys2nbrokyqd6s0ktJXS7KzXzuuvTVmP+yv+2L4i/aG+KHj3wRrvwwHga+8GoiahPF4hi1VFuWkKiAtHEqbvlkOVZvuEda+oa+Tv+CaPwfu/ht+zdZeINcV38WeObl/Eep3E3MriY5hDHr/q8Pjs0jV9Y1tUj7O0JfEkr+vX7np8jKEue84/C3p6dPv3+YUUUVkaBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeUfG79nPR/jdPpl7P4n8X+C9b06OSC31nwbrcmm3QicqXjYgMjKSin5lJGOCKyPgz+x78O/gnpPia30yDU9d1TxPE8Oua/wCIL97rUtRRgQyyTDbjO4/cC5PJyQDXt1FKys49H+u/39e47ttPt+m33dOx8rSf8E5fh5q2tWE3ijxb8Q/HPh/TpxcWXhPxP4mlvdJtmXhAsRUPhRxgucgkHIJFegfGT9lfQvi/rVrrMPi/xv8AD/WYLRNPa+8D69JprT2yMzJFImGjZVLuR8ufm64r2mim9UkxLRtr0PLPgD+zT4G/Zs0G+07wdZXH2nUphc6nq2pXBub7UJRn55pT1PLHAAUFmIGSc9t458K/8Jx4P1fQP7Y1bw//AGjbtb/2podz9mvrbcMeZDLg7HHY4OK3aKJe+rSCPu6o+RvBP/BN3wx4B+ITeNdM+LvxdPiC4uIbjULmbxLFu1MRsrCO6ZbcNNGdoBVm6cVc8bf8E6/CHjH4za/8ULb4kfEzwn4s1pv39x4a12Gz8tNqr5SMLcyCPCL8pcjgegr6too7eV7fPf8AIO/nv8jwSH9j3Q5vhe3gvW/iB8RvFBj1X+2bLxHrHiaR9Y0+4EXlL5FyiptUKXwhDDMjEg54q/CX9h/wL8LPiJH4+vNa8WfETxtbwm3tNe8c6wdRubSMggrEdqqOGYZIJG5sEZOfoWiq5mnzLf8A4Fvy0E9Vyvb/AIN/z1CvNP2iPgD4e/aY+GF74E8UXmpWOkXc8Nw82kyxx3AaJw64aSN1xkc/L+Vel0VnKKkrMpNx1R498Wf2Y9C+LFnoI/4Sjxj4N1XRLU2VprXhDXJNOvPIOzdG5UFHBKKeU6jjFN+AX7KfgX9nX+2bvw+mpav4h1tt2q+I/EN4bzUb7kn95IQBjJJIVRk8nJr2Oiru7t97/jv9/XuRyqyXb9Nvu6HyXff8EzfhRearqCx6v40sfB+oX39pXngOz154tBnnyDua3C7uoHRxjAAwABXpn7QX7KHg79o7wL4e8G6/d6to3hnRbuK6h03QJoraKXy0KRxSBon/AHaqSAF2kZ68CvaKKW0VHorP7tvusW23Jy6u/wCO/wB/Uhs7OHT7SC1tolgt4EWKKJBhUVRgAD0AFTUUU223dkpJKyCiiikMKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAory742ax8X7UaZYfCXw94Xvry5SV7rWPF1/NFZ2W0psTyYFMsrPufBBAXZyeRXjX7G37YXi342fEj4hfDH4jeGtL0Lx14MkYXE+hSSGyuVWUxPtWQsy4baQdx3B+i4oj775VvZv5Lf7gn7keZ7XS+/b7z62or44/bM+IHibxR8e/gl8EPBHiHVPD2oa3qR1zXrzRbyS1nj02ANlC8ZBCyBZuM4JjX1qP9tn9rj4tfs2rYX+geA9Ai8MTa1b6RHrGv3r3Mt+0kTSM0NtAyGNF2su+STJI4THzU4e/y2+1Ky+9K/wB7t8mOXutrsrv8X+Sv80fZdFeefGZviq/hWyb4Sf8ACHf8JEblTcf8Jp9r+yfZ9jbtn2b5/M3bMZ4xu74r5c8M/tN/tF6P+194O+C3jSx+F+ptqdq2p6pN4Rh1JnsbMLIcs88gCuSgwNrD5l9RSj701Dq/8r/kS3aHtOlr/ofc1FfKf/BRr4wa/wDDn4J6f4b8FX91p/j3xzq9toGjTWE7Q3ETO4MkiOpDKcAJuByDKDW/44H7RPgrQdH8NfC7SfCmvQ6JotsLnxN4/wBVup7jVblUZZESKH5/M+RWMkrgEy+xNTzLllN7J2/C7+5NfeXy6xj3V/xsvvd/uPo2ivjT9nn/AIKHWnxK/Zg8d/FHxjoCaJf+CHaHUrLT5S0V1JsUxeTv5Qu7bNrFsHuc1x9x+3D8bfhr4f8Ah78Tfib4J8G2Xwj8a3kFvDHo11dHV9LinUvFLcF/3b/uwz4RRnGDsPFa8r5+T/D6e98P3/8AD2Iv7vNbv6+78X3dfwPvuivnf4/+N/2itDl129+F3hPwLJ4d0az+1/bPFN/cSXOqYi8x0t4INojKnK5lkG4jPA5rzb4e/wDBSDTPEH7F+vfG7WvDn2TU9DvDpE+i2s58u6vj5fliN2GVRhMjHIYqA33sc5KScZP+W1++rsvvehfK7xS+1t22v+R9o0V8Q2P7Xfxs+FPjz4XwfG3wj4NsfCPxFuEs7C58Lz3RutJnkCGOO7EpZXP7xQdmAPmO7jB+3q0cWlfza9Gt1+K+8zUk9u1/VPr+DCiivjP9sr9rr4tfs76poc+j+A9AtfCt94gt9Ej1bXL17me/8yMu0kVvAyeSi7WXdJIWJH+rxzUr3pRgt20vvaX6jk+WEpvZJv7lc+zKK4T4x6x8QtI8L24+Gfh7SfEHiS6ult867fNa2dlEUcm4l2gvIAyouxPmO/PQGvnn4J/tVfFNf2prv4E/GDw34Xj159LOq2Ws+C5bg2hjC7trpOS/IDDcduCoG0hgaI+9LlW+v4K7/DUcvdjzPy/F2X4/1Y+waK4TxV8b/BXhXw5421aTxDpuof8ACG2kl3rdlp93FNc2YVGcJJGrZR2CnaGxmvjS+/bs+OfhT4Z+Hvjj4j+H3g+L4LazexxDTrK8uW161tZHZI53dv3LA4yAFydyghc5CTTdvTXp72i18+g2mlf19dNX9x+g1FeAfFDUv2kNT8QR6h8JJfhLJ4HuLOGe3l8X/wBp/bWZl3Mx+z/Js5BHfHWuN/YH/aa+I/7TNn8QL/xrYeFo9J0HVF0nTdS8LQ3KQXsqhzOwM8jlkwYCpwpw5yPSopycls1+jt+bJbSipLVO34q59Y0UUUhhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHhf7X37UOl/su/DF9WMK6t4t1R/sXh7QUy0t9dtgD5V+YouQWI9lHzMtcH+wT+y/rnwW0HxJ49+IVwLv4pePLj+0tZbjFmrM0gg443bnZnxxnCjIQE+qfHD9k/wCFX7SF7pN38RfCv/CRXGlRyRWcn9oXVr5SuQWH7iVN2So+9nGOK88j/YR8AfCHwt4xvvgd4Ys/CPxD1XQ7nR7HVdQ1e/lgh84AFmDyS4wVVgQhOVHYmoi3TjOdryadvTt83a7+XTW5JVHCF7Rur+vf5LZd9fTzj9jHPx+/as+Nvx5n/wBI0e1uR4P8NSscr9nhwZXTthtsTZH/AD1cVS/4LCf8kL8A/wDY52n/AKIuK+lv2T/gSv7N/wAA/CngN5be51DT4Gk1C5tSxjmu5GLyspYAldzEKSAdqrwK5v4n/sEfAj4zeONS8YeMfAv9seItRKG6vP7Xv4PM2Isa/JFOqDCqo4A6etbO1KVOMdVDl+bi03/4E7v5kRlze0nJWc+bTtdWS+St9x7brniCw8J+Gb/W9UuFtNM060e7uriQ4WOKNCzsfoAa+H/+Cbek3/xj8cfFj9pPxBbGO88X6k+maKkoy0FhCRlVPp8sMf1gPrX074d/ZZ+GHhL4O6p8K9I8NNZeA9UMpvNKTUrsmXzMeYPOMplAbaMgOBjjua7DwH8PNB+E/gXT/Cfg3SodI0TS4GisbESOyJklvmdizHLEksSSck81KahOVTf3bL5/F+SS8m9tibN040/O7+Xw/jq/RbnyBff8ZIf8FNLS2A+0+FPgzpHnSZwYzqtwBj8QCp9jbGu7/bk/ag1P4WaTpfw2+HNv/bfxj8an7HpGnwYZ7OJ8q1246DGDt3YGQzH5Uaug/Yu/Zt1/9n/w34yvvGuoabq/jzxfr1xrWrXukvI8HzE+XGrSIjEDLtyowXIGcZrW+L/7D/wT+PXjKTxX468Ff25r8kEds15/at7b5jQEKNkMyLxk84zWcofuqdJ6reXnfWVvm+X0W+xqpfvZ1FvtH5aJv/0r1Z8t/GD9kdv2bf8Agl7488I2Ug1fxJN9n1rXbyHJWaZbmBpdmefLjjjwM4yELYBOKw/21vEumeOv+CdvwK0bRLiC61TxFcaHa6bY2zBnlkS2KOqqOflchT6MQD1r7Y+Dv7Jfwn+AVj4hsvA3hCLSbPxBHHDqlvPeXN7HdRoHCqy3EkgxiVwQMZ3c5rI+Hn7DvwM+FPjpfGPhb4d6fpniKN2khumnnnWBj1aKKSRo4jycFFGO2K35lKb5vhcoS/8AAOnpsk76diI3hFOPxJTWvXnS1fnfXz7nkv7a/wC0Br2jWOh/s/8AwtjXWfi14ytRYyeW3Gk2TJtkuJCPuEruwT91Qz9lDeNftlfsw2/7N/8AwTV0/wAH6Mx1J9I1uz1PWtQVdv2maRmSSXHZQzxooPRVXOTzX1n8UP2CfgT8ZvHGo+L/ABj4F/tjxFqGz7Vef2vfQeZsRUX5Ip1QYVVHAHSul+Gf7J/wn+D/AIL8QeEvC3g62s/DfiA51TTby5nvorr5NmGFxJJxt4wMCsPe5XL7bafk+WSaXku+93rbtcWoSgl8MU196s35vottD5T/AOCgWtaf8TI/2WdE8O3kF9qGu+KbHUbGGzYOTahEzMMfwDeOenB9DX6D14p8I/2L/gt8C/FMniTwR4DstH11lZFvnuLi6kiDAhhF50j+XkEg7McHHSva62fLZ26ycvvSVvuW/XsjCMXG3kkvuu7/AI7fiFfBf/BXb/kmvwl/7Hq0/wDRM1felfPfxK/YC+Avxf8AG+qeL/F3gT+1vEWpur3d5/bF/D5jKiop2RzqgwqKOAOlQm1OEuzT+5p2+di5RUqc4d0196aPTvi9oWmeNPB8vhO/8Zan4Hn12RLa01LQdUXT9S8xWEuy2kIJ3lY2yACSm7618EfDnw7cfso/8FJ9G8EaJ4juPibD460ppNW1LxL5d7runbY5GG+8Ch9v+jxttOFKkZXIVq+xov2N/g1H8JIfhk3gWzufBMFy95Bpt1cTztDO+d0kczyGVGO4jKuOCR0NXfgv+yh8Jf2ebi5ufh/4JsdAvblTHJfGSW5uShIJQTTO7hSQDtDAcDinTtCrz9PzurW8tevl0CV5UnDq/wANVr56Lb8zxH9pj4XfDGH4I/tN3vw5j0m4+IGqaU1x4pj07Uzc3SyRgygSw+Y3kEqJDtCpu54NeDfHbxrour/8EevAtlZ3lvJeaja6RpNrawsGeW6hnTzY1Uclh5MhI9q/QTwf8CfAngHxj4v8VaF4ehsde8XSLLrd2ZZZftjDdjKOxVB8zZCBQc85rgvC/wCwj8BfBfj+Lxpo3w10uy8Qwz/aYZvNneCCXOQ8du0hhjIPIKoNpHGKyjTTSjLRPkvbpyNuy8nfTa3Y0lLVyjv72/XmSV35q3nc8z/bI+L17+zR+w3p2lQyOvjHVtJs/C1gsZIlE724SaRcZOVRZCP9or617F+yB8E0/Z8/Z18GeDGjVNSt7QXOpMv8V5L+8m574ZtoPoorofiZ+z/4B+MXiLwprnjHQBreo+Frk3mkPJdzxx28xZG3GJJFSTmNPvqw49zXoddHO5OpOXxTd/ktl97bfy7GCgoxp01tBfj3+5JfeFFFFZmgUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUV8//FL9vX4E/Bfx3qfg3xl45/sbxJpvlfa7L+yL+fy/MiSVPnigZDlJEPDHGcHkEV3Pxg/aI+H3wE8G6b4q8d+IP7C0HUbmO0tbv7FcXHmSvG8irshjdhlI3OSAOMdSKAPR6K84+DH7RHw+/aE8Maj4h8AeIP7f0fT7lrS5ufsVxbeXKEVyu2aNGPyupyARzXCfDL9vr4D/ABi8caX4P8IeO/7X8R6mzraWX9j38HmFI2kb55YFQYRGPLDpjrQB9BUV4h8Zv21Pgz+z74ti8M+P/GX9ga5Japepa/2Xe3OYXZlVt0MLryUbjOeOnSuo8VftEfD7wV8HbL4p614g+x+A7y2tbuDVvsVxJviuNvkN5SxmUbt68FMjPOOaAPR6K8q+Bf7Unww/aU/tv/hXHib/AISP+xfI+3/6BdWvk+d5nlf6+JN2fKk+7nG3nGRnj9P/AOCgHwE1X4kQeArXx55viyfVRoken/2PfjdeGXyRF5hg2D958u4tt75xzQB9C0V5F8cP2s/hT+zfqGlWXxF8Vf8ACO3WqRPNZx/2dd3XmohAY5gicDBI6461raf+0R8PtV+Cr/Fq18Qeb8Pltpbs6x9iuB+6jkaN28kx+bw6MMbMnGRxQB6PRXjHwT/bE+EP7RfiK90L4eeLv+Eh1WytTez2/wDZt5bbIQ6oW3TQop+Z1GAc89KwfGn7f/wE+Hvj3UPBfiDx5/Z/iWwuhZ3Nj/Y9/JsmOMLvSAoeo5DEe9AH0LRXmfxw/aS+HP7OGm6XqHxF8Rf8I7aanM8FpJ9hubrzHVQzDEEbkYBHXAqX4b/tD/D74ufDbUfH3hPxB/avhLTzOLnUPsVxD5fkoHl/dyRrIdqkHhTntmgD0eivB/hJ+3N8Efjp40t/CXgfxt/bfiC4ikmjs/7JvrfciLuc75YEUYHqaT4tft0fA/4G+Nrrwj438bf2J4htY45ZbP8Asm+uNqyKGQ74oHQ5Ug8H60Ae80V5x8TP2h/h98Hvhzp3jvxf4g/sjwpqDQJbah9iuJ/MMyGSMeXHGzjKqTyoxjnBqP4IftH/AA6/aO0rU9S+HfiH/hIbLTZlt7qX7Fc2vlyMu4DE8aE8dwCKAPS6K+evA3/BQD4CfEnx3p3gzw548/tHxJqFwbW2sv7Hv4vMlAJK73gVB908lgOK3fjZ+2P8H/2dfElnoHxC8X/8I/q15aC+gt/7MvLnfCXdA+6GF1HzRuME546dKAPaKK841X9oj4faJ8FU+LV74g8n4fPbQ3a6x9iuGzFLIscbeSIzLy7qMbMjOTgZrK+B37WHwq/aQvdWtPh14p/4SK40qOOW8T+zru18pXLBDmeJA2SrdM9KAPXKK+erv/goB8BLH4kzeAZ/HmzxbDqzaE+n/wBj35xeibyTF5gg8v8A1g27t23vnHNdd8c/2pvhf+zW2ir8R/E//CONrImNj/xL7q687ytnmf6iJ9uPNT72M7uM4NAHq9FeceGf2iPh94w+Dd38VdI8Qfa/AVrbXN3Nq32K4TbFblxM3lNGJTtKNwEyccZ4rmfgv+2l8Gv2hPFk/hr4f+Mf7f1uG0e+ktf7LvbbEKsiM+6aFF4aRBjOeenBoA9tor57+JX7fnwG+D/jjVPB/i7x3/ZPiLS2RLuz/se/m8ssiyKN8cDIcq6ngnr613vxq/aI+H37O/h3T9d+IPiD/hH9K1C5FpbXH2K4ufMlKM+3bDG7D5VY5IA4oA9Horzj4RftEfD747+CdS8X+BvEH9ueHdNuZLS6vPsVxb+XLHEkrrsljRzhJEOQCDnA5BFcR8K/28vgV8avHWneDvBnjn+2fEmoCU2tl/ZF/B5nlxtK/wA8sCoMIjHlhnGBzgUAe/UV4Z8Yv23Pgr8A/GB8LePPGf8AYWvC3S6+yf2Ve3H7p87W3wwuvO08ZzxXWeNv2iPh98OvhPp/xL8Q+IP7P8E38NtPbap9iuJd6XChoT5SRtINwYdVBGecUAej0V5d8Df2nPhp+0lb6xP8OfEn/CRRaQ0SXrfYLm18oyBig/fxpuzsb7ucY57Vxfh/9v8A+Anij4h2ngbTPHn2nxTdah/ZcNh/Y9+m6537PL8xoAg+bjcWx70AfQtFePfG79rr4S/s46xpul/ETxZ/wj19qMDXNrF/Zt3c+ZGG2lswROBzxgkGtpf2h/h8/wAFf+FtDxBn4ffZjd/2x9iuP9UJPL3eT5fm/f4xsz36UAej0V458Ef2vfhJ+0brWo6T8O/Fn/CQ6hp9uLq5h/s27tvLiLBQ2ZokB5IGASa53xJ+3/8AATwh8QrzwPq/jz7J4os77+zZ7D+x799lxuCbPMWAofmOMhse9AH0LRXl/wAcv2mfhr+zda6Rc/EbxJ/wjsOrPJHZN9hubrzWjClxiCN9uA6/exnPFdf8PviBoHxU8F6T4s8L3/8Aanh/VYfPs7zyZIfNTJGdkiqy8g9QDQB0NFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRXKfEj4reD/g/4dk13xr4k07w1pSZAuNQnEfmMATsjX70j4BwqgsewqH4S/F7wl8cvBNr4u8Eat/bfh66kkiivPs01vuaNirjZKiuMMCORQvevboD0tfqdjRSEhQSeBXlPwf8A2qfhX8fPEOuaH4C8Ww+INU0Ubr63jtbiHYu8puVpY1WRdwxuQsORzyMi1fKtwei5nser0UUUAFFFeVeKv2kPDHg/4/eDvhBe2eqP4m8U2U19ZXMMMZs0SJZGYSOZA4YiJ8YQjpyKFq1Fbv8ARN/kmHRy6Lc9VooooAKKKKACiiigAooooAKKKKACiivnz9sf9rnw3+y38N9Uu5Na0pfHc9m8uhaHfLJMbuUHCl44iGEec5Yso4xuzUTmqa5n/XoVGLk7I+g6K8y+Dnx98I/Fv4O2Xj+w8R6Xc6THaB9Uvo2MEFnMkYadXEh3RhCScP0GDkg5PNfDX9t34HfF/wAbf8Ij4S+IWn6p4hYssVm0E9v55XORC8sapKcAnCFiQCelbSi4zdPqv6+4yjJSgqnQ9yoorwHxB+3r8APC3jp/B+p/E3SbfXY5/s0qLHPJbxSZwVe5WMwoQeDucYI5xUbtRW7L6N9Ee/UVw3xW+OHgT4H+E08S+OPE1l4f0aRgkVxMWczsRkLEiBnkOOcICcDPSqXwX/aJ+HP7Q2k3eo/D3xVaeJLe0cJcpEkkM0BOdu+GVVkUHBwSoBwcZxQveul038geiTfXY9GooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAPP/AI3eFtG1r4e+IdS1HSLG/wBQ0zR9Qexu7m2SSW1Z7dg5iZgShIABK4yBXz1/wSZ/5Mp8Mf8AYQ1D/wBKXr2r9pLQ/i14m8FHR/hQ/guO51COe01R/GRuwgt5IymYDbgnfkn7wIryP9hH4B/G79mnw1b+A/Gd54Av/AVnHcz202hS30mqG6llDgO0saReXgydF3fd681FBWq1W9E4pL1Tbf8AXcdbWFNLo2/k1Y9A/bi+MDfBH9l/xz4itpmh1aazOm6aUPz/AGq4PlIV913F/ohr4t8N/C8fsG/Hv9mDXhELHTvFmhDwp4ndVAU30rCQs59fNmj5P8MB9K+sP2x/2Xdf/ao1n4Y6HJfaZB8N9I1g6p4lsri4nju71VAWOOHy0xyrTKSXQjeCORXlPx8/4JPfDDXPhvdw/B/w9aeDPH0c8M1hql/rOoyQKFkBdX3PLjK5wQhIYL05p0n7OXtZL7S9eVJp6efPLr0Wnd1EqkVTT+y//Am01r5cq6dXr22fjJ8ZPjNd/t0Wnwb+H/inTNB0fVvCC35uNU0yO6XTZfOk8y7jXCvLJsjCLG7+X82SOK5z4YftPfFjQv8Ahpf4Z+O/ENnr/jj4b6Dd6vpHiqz06K3M6C3aSNpIFXygV3QsF2nqwO7GTwvxF0L4qXn/AAUe8DQ+Hdf0HSviXZfDaCW5mvoJbnSrydDMJ4XxskETsTh1AYYBx2r0zTf2X/FXwr+E/wC0x8TfiVr2l698R/G3hrUvtY0OORbCzgS0l2RRGQB2GAg+YDARRycsYn7lKTb05amvdqTUWvS3k7b6WKo/vK0I215qenZWi5J+t/Ndtbnldx+0N+1Av7H+hftFr4/8Px6Xp3kpdeFv7BhY6rCLgWz3E9xwUkaXJ8uFY1CEYbIweu8UeNoPiT/wUO/ZS8XW8LW9vrvgq41NIW5KLNaXcgX8N2K83/Z8/Zw+OP7QX7EvgnwLZeOvCth8I9dka6vGurKf+2bOOO8djbRbcxSxmSMSAsUbJ252jB+rtX/ZE1WD9qf4J+PdAvNMtvBPw/8ADsuhPY3Msn21x5E0UWxRGUIAkXJLqeDwa75JU67urWlK3kvZzTv/ANvNW6b20OaMufDyXVwa8n70eX52Tv5WvqfI3jT/AIKQeI/GPibx7qOnfHDSfhHa6Dez2vh/wjL4Nl1Z9bSLO17i68pxB5jDb8p+XJyBjc36Cfsm/Gq6/aH/AGe/B3j++sY9O1DVrZxdW8OfLE0UrwyMmSSEZoywBJIBAyeteDeEP2XPjz+zb4q8ZW/wR8T+AbvwL4m1WTWDpvja2vBPpk0nDiE2/DjAUfORkIvAOSfrbwHpuv6P4P0qz8U6zD4h8QxQgX2p29qLWOeXJJKxAkKozgDPQc81y0tKKUt7R++3vfe/O2isjWrrVfLtd/dfT+rX3ub9FFFABRRRQAUUUUAFFFFABXwL+0z8Pfi78F/2vof2iPAngVPitob6GNMvdFilxe2QUAMYFAL84BDRrIfmlBUAg199V8e/tWfFL9oL4K/Efw6fBGq+CNa8N+Odcs/D+k6Z4i0+4Fxpd1JFhmMkDrvizG8hZtzDdgKQKjXng47309X7tvnexatyTUtra+iaf4WueEftVftVeEvjx/wT78b654C02XwpfXniCz0/xJpc0CQ3Mc7OrOZCnEm9YlG88kLggEEDov8AgoX4d0/4e/Cv9mXVPDVnDaahoHibTLPTJrSMIyReRv2LjnBaGM474r0Xwz/wTngb9m34k+BfFfipdT8ZeP8AUf7c1TX7W1CQW98JPNj8qLIzGr7s/dLB2xt4AqaL+yH8afid4m+F8Hxu8X+EL/wX8OriK8sLPwvDc/atWuIVVYZLxplCqRsBPljBywxzuG1NKNSz096nLySilzJejTt3uYVOaVPT+WpHz95+6/mrX9D7O16zn1LQ9RtLWb7Pc3FtJFFNkjY7KQrfgSDX5IWB8R/Bn9hP4lfBPxr8CPGS6/Cb2+n8ULpkbaKSHWRLp71nAZkCgAKGJCqAecD9I/DXhv4wWv7QvinV9a8WaLefCG409I9F8P29sFvrW6Ai3SSP5QJXib/lq2d6/KuK8N+KH7Pv7TP7QujT+APH/jj4faJ8OLq4Q3994Tsrwavf26OGETJMTFHuwM7W4I/iGVPNKDkny/bjZ36a9ezW+m6tbU6YyUWr/Yd9OunTv212fkfOPwn1S78fftHfsS6J4mdbyy0/wE2qQW90N4ecRXSxvg/xBbaBgf8AYr2rwRCPC/8AwV28c2elxm2s9b8Fx3moQxDEcky+QBIQON3y9euWb1r0X49fsd6xqmufCnxl8G9V0jwv4y+G9v8A2dpdrrkUj6fdWWzy/ImaMF1AXcMqCSHbocEan7N/7M3i7wf8XPGXxi+KuuaPrfxI8SW8eniDw7FKmnabaJt/dQmX523eXHksBjb3JJrs5lOoprSzqN+fNzW+/mV+3L6HM48sOXe8aa9HG1/yf3n0xRRRWJoFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAYjeB/Dkni5PFbeH9LbxQlt9jXWzZRm9WDJPlCfbvCZJO3OOelaWp6ZZ61pt1p+oWkF/YXcTQXFrdRrJFNGwKsjqwIZSCQQRgg1ZopdLDvZ3RmeG/DOj+DdFtdG0DSbHQ9ItVK2+n6bbJb28IJJISNAFUZJPA6k1p0UVTberJ20QUUUUhhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB538Z/jz4S+A+i29/wCJpr6Se7Ev2LTNKsZby8vGjTe4jijU/dXks21V7sKh/Z5+Pnh/9pb4X2HjzwxZ6lY6ReTTQRw6tFHHcBonKNlY5HXGRxhunpW78XAP+FVeMzjn+xL3/wBEPXzP/wAEmf8Akynwx/2ENQ/9KXqaT5qlWD+zFNfN2HU92NOS6tp/JXPqD4j/ABI8NfCPwbqXivxdq8Gh6Bp6eZcXlxnAycBVUAszEkAKoJJIABr5rj/4KY/Dm3hstU1nwV8SvDfgy9kVLbxpq3hd49HmDfcdZVdmKt2wmfavP/8AgrZIbrwv8GNIvnZfDeoeNIE1JT9xlC4AbkD7rSnBPb2r6L/bM0vSpP2RPiraXsFuunQ+GbsxxsoCIyREw7R2IdU247gYrN1OWnOq/su1vSKk9fnZfqXGKnUhRX2knf1bS/K7PY9J1ay17S7TUtOuob7T7yFLi3urdw8csbAMrqw4IIIII9at1+Sk3xG+JPhH9hT9k/8A4RbxVqPhXXtU8TtpkdzFM6xvA088cAmjBxLEF2HYwKkKOK+kP2gtPsf2bPhP4b8L698evirPea7rMrj+ymTUfEutO0aqbWzlKD7PGrlWAA437c5YV01YqnOpFfZlyrzfu/pL/K5z0pOajfdq7/H/AC08tXY+26K/OL9h341eMZP2mviL8M7zV/iVd+EofDZ1mws/i0mNes5laBSWOSdjecxHIGApwDknyz4XyfFn4kfsK+Lvi7e/Hjx7Zax4NuLxtKsrPUisUwhdZH+2SHMtzu8wqoZ9qBQMEZFRK0Yub2UeZ+l3F/c0apXaj1cuVerjzL8D9cKK/NH47/tQ+ItY8B/sxS+LvH+s/DfwX420aXUfFev+D28vU/OjgQgx+WryRxl2yxRCBvOc4Aqv+zf478Y/Dj4WftCfGpfHHxD8eeEtDt5rXwTN421K4ltdRiyCtybeYAllcRjzF2gqzjaDkAlamqkpbQ5r/wDbrt+L2vutRR972fLvPlt/29f8ra9tEfptRX47eH/jD8cpPCPhX4heEv8AhpDxX8RLqeC/vrfUdAM3g2/t3O6SO3hiztQqQFdV5GSAmQR+wdnM9xaQSyRmGSRFZo26qSMkH6Vo4OMbvvb+vInmTaS6q5NRRRWZQUUUUAFFFFABXxL+0Z+3LeWfxJ0jwn8I9M8XeLpfCviK3bx1c+FfDo1OCGwUOJ7XeVbbKSByoXGxgHBBFfbVfnH4o+Gnx7/YG8afEr4h/DWy0X4i/CrXL+bxBrGjXjmK+sky8krg5B+UMw3qZMgAmPjNRzcs05OyWvldNWT8rXv9xfK5Qairt6edmne3ntb7z6/8e/tUfD34cfBvSPiZrGo3S+HtZjgbS4IrV2vb6SZd0cMcBwxkIzwcYwckAZrE+B/7ZHg344eNtQ8Fx6L4q8D+NLO2+2t4d8Z6SdPvJLfj96i7mBX5h1IODnGOa+Sfj58btL/aN+IX7EfjCzguLLw5rviKa6ewuPm8q6iuLaMoxxhisisobHIOeM133x0je3/4KufAOayXbczeHbxLkoeWhCXv3vbk/wCRXRGD50pq3NKcbduWN9/XfyMpP925RfwxUvW8rW8tPxPtrxZ4q0nwL4Z1TxDr19FpmjaXbPd3l5MTsiiRSzMccngdBye1fMnh/wD4KUfDLWNa0GC+8OeO/DPh/X7oWekeLtd8Ptb6PfyMcJ5U28kgnuVAA5bABr1T9rhvB3/DNfxCj8fajcaV4Tl0qSK9u7NQ06bsCPylPDOZCgVTwSQDxX5cNq/xK034c/s/wfHzSb61/Zw0vVoJ9L1bT7WBNQmQK32L7aiyuY0EeThQGKFuXfaayo+/W5JbXivvbvr3slyrqy6iapc0d/e/BJrTtr7z6aH6XfG39sXwd8E/GVp4ObRfFPjrxlPam+bw94K0k6jeQW3TzpF3KFX8c98YINdj8B/j54P/AGjvAcfizwXey3On+c1rcW91EYbi0nUAtDKh+6wDKeCQQQQSK+Wf2XbmPVv+CkX7TN7cyGa8jstOitXYZxbmOL7p9MLF9ai/4JrrLb/Fr9qe2hXZpMfjeTyFU/IH865D4/AJ+lFH36cZS+1Hm9PeSt9z+/7iKklGTUdoyUfW8W7/AHr7j7wooooKCiiigAooooAKKKKACiiigAooooAKKKKACiiigDyn9ob4X+O/ix4Vh0XwT8TP+FaiXzYtSm/sGDVfttvJGUMW2Vl8vqTuU55rzf8AY+/ZJ8b/ALKtqmg3Hxg/4TDwJBDP9m8Of8IxBY+TcSSK5n+0iWSVv4xsJx8/bAr6eopQ/dylKO73/r+tddwl7ySfTb+v6002PMv2iP2e/Cf7TXw1u/Bfi+Kf7FJItxb3do4S4tJ1BCyxsQRkBmGCCCGII5rwHUv2DfiD4+8PWngz4jftHeIvF/w3gMYfQLfQ7axublIyCiT3oZ5JRwM7gckA8EAj7LooSSb8/u9bbXG22l5ff9+589fHT9j7Sfi34f8AhRoWjasng3Rvh/rNpqdpZwWP2lZYoFCrbjMibOAPnO76Grn7UH7LP/DQl54L17R/F934D8b+Dr1r3RtdtrRLxYmfbvV4HZVcHYnUjoc5BIr3mim9Xe+t+a/W+mt/khK0dEtLW+Wun4s+W/gv+xXq/wAM/j1rnxX8RfFLUPHviLXPD7aNqDX+lRW26VpI2E0flvtjjCQoohCnHJ384pvw1/YbX4d/sjeMfgePGjX/APwkTXjHXjpfl+R54Uf6jzju27B/GM57V9TUUStKDg9muX5Xvb72PW6l1Tv87Wv9x+Vv7THw70j4E/FL9nzw34z8V+MPA/gfwl4Tl0uf4o+EYri2uJ5juVbdfKEvkfdBIAdiJcdBkel/sbrrnxv8RfGPwfdeJvGPxN/Zw1HTFstJ8QeOPN+2XUsiKsohmkRHZRmXnA27YzhSTn9B6KI7SU9b83o+Ztu/pfS1iWtuTS3L8uW23rbW9+x8i/D/APYp+JXw50/T/CelftJeJbf4Zae+LbQLfQ7SO/jh3bhENRyZFHb5VHBwAK+uqKKpybVn/XzEopO6CiiipKCiiigAooooAK+CvHvwD+O/ir41X3wh/wCFzeMH+Deu6Jcalf6pceH7eZole4MZ0wX5XcXZCTywITjYwr71oqeVOSctd9Ojuuvzs/lbZspSaTS3016qz/pfPvY+aviR+wn4M8YfA/wT8PdA1K/8IT+B5473w5r1qFlubS5UljK4OBJvY72AK5bBBGMVP8Ev2Rb/AMC/Fm9+KfxE+Id78VfiJJYDS7TVLjTIdNgsbXukVvEzKGPOWz/E3GWJP0dRWnM+Zz6u7+bVm/K60duhnyrlUOi/R3Xrrrr1Pm3T/wBju6174UfEzwB8SfiZ4g+IuleMdQe8guL7Mc+kR7leOKAu8g+R1VhgKnGNgGRXnTf8E7/FHjDRfDXg/wCJPx41nxv8MfD00Mtl4Xi0K2sHZYV2xJNdK7PKoX5TkZweCpwR9r0VMfcacelv/Jdn6rvuW25Kz8/x3+T7bHzD8V/2M9U174yS/FL4W/E29+EvjC+05dK1SWDSINTtr2BQoTMMrKFcBEG7J4RcAHJPof7M/wCzjoX7Mvw/l8O6TfXmtX99eSalq2tagc3GoXcmN8rY6DAAC84A5JJJPrdFOPuqy/rW9vS+ttril7zTf9WVvy09AooopAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRXz/APFL9kP/AIWh471PxP8A8Lq+MHhL7d5X/En8LeKvsWnW+yJI/wB1D5Tbd2ze3JyzMe9dz8YPgv8A8Le8G6b4f/4Tvxr4K+xXMdz/AGp4P1f7BfT7Y3Ty5ZdjbkO/cVxyyqe1AHo9FecfBj4L/wDCmvDGo6L/AMJ3418c/bLlrn+0PGmr/wBoXcGUVPLik2LtQbdwXH3mY964T4Zfsf8A/Cs/HGl+Jf8Ahdnxi8V/YWdv7H8TeK/tmn3G6NkxLD5S7wN24cjDKp7UAfQVFeIfGb9l3/hcni2LXf8AhbnxT8DeXapa/wBmeDPEv9n2TbWZvMMXlNmQ78Fs8hV9K6jxV8F/+Eo+Dtl8P/8AhO/GukfZba1tv+Eo0rV/I1yXydv7yS62Hc8mz94235tzdM0Aej0V5V8C/gF/wo3+2/8Ai4/xA+IH9qeR/wAj1rn9pfZPL8z/AFH7tdm/zPm652J0xXH6f+x3/Z/xIg8X/wDC7vjJc+Tqo1T+wbjxZv0t8S+Z9maDyeYP4PLz9zjNAH0LRXkXxw/Z2/4XdqGlXX/CzfiN4B+wRPF5PgfX/wCzY7ncQd0y+W29hjAPGATWtp/wX/s/4Kv8Ov8AhO/Gtzutpbb/AISy41ffrw3yM/mC72ffXdtVtvCqB2oA9Horxj4J/s0/8KV8RXurf8LV+Jvjz7Vam1+w+NvEX9o2sOXVvMjTy12yfLjdnozDvWD40/Y7/wCEz8e6h4o/4Xd8ZNC+2XQuf7G0XxZ9n06HGP3ccPknanH3c9zQB9C0V5n8cPgf/wALu03S7P8A4T/xz4B+wzPL9o8D6z/ZstxuUDbK2xt6jGQOME1L8N/gv/wrn4baj4P/AOE68a+KPthnP9veJNX+16rB5qBf3U+xduzG5Pl+UknmgD0eivB/hJ+yf/wqXxpb+Iv+Fx/Frxn5MUkX9k+LvFH26wfeuNzReUuWXqDng0nxa/ZN/wCFseNrrxH/AMLk+Lfg3z444/7J8JeKPsNhHsULuSLymwWxknPJJNAHvNFecfEz4L/8LK+HOneEv+E68a+FfsbQN/bvhnV/seqT+WhTEs+xtwfO5uOWANR/BD4I/wDCktK1Ox/4T7xx4++3TLN9p8caz/aU1vhcbIm2LtU9SOeaAPS6K+evA37Hf/CD+O9O8T/8Lu+MniD7HcG4/sfXPFn2nTp8gjZLD5I3Jz0z2Fbvxs/Zn/4XV4ks9Y/4Wt8TvAf2a0Fp9g8E+I/7OtZcO7+a8fltukO/buz0VR2oA9oorzjVfgv/AGp8FU+HX/Cd+NbPbbQ23/CWWur7NePlyK/mG72ffbZtZtvKsw71lfA79nj/AIUje6tc/wDCzPiL4/8A7Qjjj8nxxr/9pR22wsd0I8tdhbdgnnIA9KAPXKK+erv9jv7X8SZvGH/C7vjJD5urNq39gw+LNulJmbzfsyweTxbj7gjz9zjPeuu+OfwA/wCF4torf8LI+IPw/wD7MEwx4F13+zRd+Zs/1/7tt+3y/l6Y3v60Aer0V5x4Z+C//CNfBu7+H3/Cd+NdV+0W1zbf8JTqer+drkfnFz5iXWwYePf8jbfl2r1xXM/Bf9l//hTPiyfXf+Ft/FLxz5to9p/ZvjTxJ/aFkm5kbzVj8pcSDZgNngMw70Ae20V89/Er9j3/AIWT441TxJ/wu34x+Fvt7I39keGvFn2PT7faipiGHyW2A7dx5OWZj3rvfjV8F/8AhdHh3T9J/wCE78a+BPsdyLn7d4K1f+zrqf5GXy5H2NuT5s7cdQD2oA9Horzj4RfBf/hUngnUvDf/AAnfjXxn9uuZLn+1/F2r/b9Qg3xJH5cU2xdqLs3KuDhnY964j4V/si/8Kt8dad4m/wCF0/F/xd9iEo/sfxV4q+26dPvjaP8Aew+Uu7bu3Lzwyqe1AHv1FeGfGL9lf/hcHjA6/wD8Lf8Ait4J/wBHS3/svwd4m+wWPy5+fyvKb5znk55wK6zxt8F/+E1+E+n+Bv8AhO/Gug/Y4baL/hJNE1f7NrM3kqF3SXOw7mkxlzt+Yk9KAPR6K8u+BvwI/wCFH2+sRf8ACw/Hvj/+0mibf451v+0mtdgYYgOxdgbf83XO1fSuL8P/ALHf9gfEO08Wf8Lu+Mmo/Z9Q/tD+w9Q8Webpknz7/IeDyRmH+HZnpxmgD6Forx743fs4/wDC7NY02/8A+Fo/EnwF9igaD7L4I8Qf2bBPlt2+VfLbc46A+lbS/Bfb8Ff+Fdf8J141P+jG2/4Sw6v/AMT7/Wb/ADPtez7/APDu2/d4oA9Horxz4I/s3/8ACk9a1HUf+FpfErx79stxb/ZPG/iH+0YIMMG3xJ5a7X4xnPQkVzviT9jv/hJPiFeeK/8Ahd3xk0v7Tffbv7E03xZ5OmRfMG8lIPJO2LjG3PTjNAH0LRXl/wAcvgV/wu+10iD/AIWF488Af2c8j+Z4G1v+zXud4UYmOxt4Xb8o4xub1rr/AIfeD/8AhX/gvSfDv9uaz4k/s+Hyv7V8QXf2q/ueSd00uBvbnGcDgCgDoaKKKACiiigAooooAKKK8x/aM/aA8Ofsz/CzUPHPiaO5ubO3kjt4bOyVTNczyHCRpuIHqSSeApPPSplJRV2VGLk7I9OorwT4LfHz4m+PPFVppfjn4Eax8OtO1C1e6sdYGs2+qW5CgNsnESq1u7AjCsMk5Have60cXHczUlLYKK+cf24P2kvEf7MvgfwdrfhvT9L1G41jxLa6Pcx6rHI6LBIkjMU2SIQ/yDBORyeDX0dUrWPN52+dk/1RT0ly+V/k21+jCisbxlqmr6L4T1e/0DRP+Ek1u2tZJbLR/taWv22YKSkPnOCse44G5uBnJr4xu/2/PjLY/GKy+Fc/7MWzx7e2J1KDSf8AhP7I77cb8v5og8of6t+C+eOnIpJ3lyrf/h/0TfoD0XM9v6/zPueiuc+HeueIPEngvStT8VeGf+EO8QXERa80P7fHffZH3EBPPjAWTgA5A747V0ROATVS91tPoKL5kmhaK8q/Z3/aO8M/tMeGdc1zwtZ6pZ2ekavNos66tDHG7zRKjMyBJHBQiRcEkHrkCvVaOz7pP5NXX4D2bXbT7gor5v8AG37SXiTw1+3H4C+DNvYaXJ4Z8QeHptVubyWKU3qTJ9pwEYSBAv7heChPJ5r6Qo+ypdHf8G1+aCXuycHurfik1+DCiivOv2gPjp4d/Zx+FeseO/E4uJNN08Ii21ooaa4ldgscaAkDJJ6kgAAk9KiUlBXkVGLk7I9For4y/Zd+JXxx1D4zeINV+Inwv8T6R4M+IM8N5oU8uuRaja6BHHaMwikhVt1usu3JYon7xlUqSc10H7Tn7dVz+zvrunWUfwr1/W9OuNZh0STXb+dNNsWmkTeBblleS4woOWCKmVI354rXlalGD3lbTs3ZWfazdtf1Mudcsp9Fd38lfVd7pX0Pq2iivFPjR8VvjH4H8UW9j8P/AIF/8LM0Z7VZZdW/4S+z0ny5izAw+VMpY4AVtw4O7Has72NEr3Pa6K+S/wBn/wDbuuvilqfxYg8bfD5fhzZfDa3MutXy69HqsaSKZPMi3RQqpZRE5+VmyRiuXt/+Ckuo6fpvhzxr4m+C2ueGvg34iv1sdP8AG02rW8snzMwSWWyVd0aHax3FyMD5d3ANJczSXW1vnovv6d+gnpe/S/4K7+7r26n25RTY5FljV0YOjDKspyCD3p1IAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAryf9qD9nbRf2ovhDqXgXWryfTFnkjubTULZQz2txGSUfaSAw5IK5GQxwQcEesV558bfgfofx38M2ej6zqGtaNJY3i39jqnh7UHsr2zuFR0Ekci552yOMEEfN0qJxUlZq+39fLcuEuV3Tt/X9XPkH4K/FL44/sy/tMeC/gL8Vtd0/wCI3hvxNay/2F4hhUrewJEj7fNJAZv9Xhg+8/OCJGAIrnf2KbuO0/ZT/areeZYRFr3iAu0jBdn+hjkk9K+pvg7+xb4J+Efj4+Op9a8V/EHxutubS38Q+ONYbUru1hIIMcR2qqggkZ2kgMwBAYg8trn/AATj+FmueNvE+uvqPi2y0rxNcG81jwnYa20GjXtwSW82WBV3OQ5LhS5UH+HHFKrF1IOMndyhKLfrKLXrorN9X5ajpSVOalFWSlFpeiafpvoux8E+PITe/wDBKv8AZ6hN1JaGTxrJH9pjba0Wbm/G4HsR1H0r3T4mfCvTP2Qf21v2fbr4bajrSz+OLqXTvEsN9qs142rKGiVriYyMxZz5zMf4QyKVC85+k779gH4aap8CfBHwjv7vXr3wj4T1b+17ZZrqHz7tzJM7RTsIQDG3nuCEVGxjDDrVr4X/ALCfw9+F/wAULTx6NV8VeLNb02A2mjL4q1hr+HRoCGAitQyhlUKzKA7NgHjkk12yqReIdVbc7l6rlSt83/wdkcsot0nDry29HzSafyT/AEW7Nb4eftWf8LC+I8XhH/hT3xY8NeY8yf294i8MfZNLXy1Y5M/mnAbbhTjksvrXgHi3/lMV4K/7EWT+V3X3pXkuo/sz+FtT/aS0v42y3urL4s07SW0eK0SaP7E0J8z5mQx79/71uQ4HTiueHuzg305r/OMl+bRpUXNGSXVxt8pRf5I+Z/2sFn+OH7cnws+BPiPU76z+Gt5os+tajpdndyWw1eVfPKxSMhBKjyF4B4y5GDgjl/APwo0H4Vftx+LP2etBN/c/Brxb4JkvdR8Jz6jPNBaSNlG8ty5kjLKOW3Bj5o54XH1t+0B+yp4L/aMm0PUNdm1jQfEmhOZNK8SeG742Wo2WSCQkmGGCQDypx2xk1H8B/wBk3wV8Ada1rxBpl1rnijxhrSrHqHinxXqJv9SuI1xhGlIUBeF6KM7VznaMRTiuXllp8d+vNzXtf0ut9uXTcuo3J3i/5bf3bWvb1s/v12PjH/glp8Ifh14f8A/ET4r6jpbWviDwzr2q6dDrKXdxutdPS2iZlEYfYxAZzuKluevSvnL4zLayfByL40/Db4SeMtBhh1KI2fxk8QePDNql46zGMmSy3Hl2BG5MAEdcZFfqB8Pf2I/Avwv+IviTxPoOseKoNM8QvdS3/g6TVd2hSyXClZZDbbAWbBIG5iFzgAADHm+o/wDBKz4U6p4ZvPDU3ir4hnws0rT6foJ8Q77DSJWfc0lrC0RUMQXXMgfh274YK83yS2ajD5OPxeeu6t1b5rl+5eatpKUvue33bPfRaHHeML6XVP8AgqR8BLychp7jwBJNIQMAsyXpP6mvvyvH7r9l/wAKXnx08H/FeS91f/hI/C2inQrK3WeL7I8BWQbpF8vcXxM/IcDpxXsFdM5RaSj0cvxnJr8GjBJ83M+0V81FJ/igry/9pP4A6L+0x8IdZ8Ba7cz2FvfbJYL62AaS2njYNHIAeGAIwV4yCRkZyPUK8/8Ajd8G9I+OHgk6Bq15q+mmG4S+s7/Qr9rK8trhAwSSOUZwcMw5BHPSuSok46q/9dPPt5m9NtSunb+vy7+R8YeBfiN8dv2Mfjz8M/hJ8SPEunfFDwB4vn/svRdWWEx6haBNiLv/AIvlLx5DmT5Tw4IIrb/4K7f8k1+Ev/Y9Wn/omauu/Y5/Y1vfC9r4e+JPxnuvEfij4yWi3EUR8T69/aqaTGZZFjEBDsuWiKsSWbBc42niuk+PP/BP7wv+0V4uudc8U/Er4mRW73Ud5baHY69ENNsJkjCB7aCSBxE2ATkHOWbnmuptxlT53eUZJt+Skml5vR6nNKCaqRjonFxS87NN+m1l8+p9RV5J+1b8cLb9nf4B+LvG8rL9ssrQxafE3/LW8k+SBcdxvYE/7Kse1cj40/Yl8M/Eb4H6f8MfFXjnx94j06z1Qasutapra3GqSSDdtjeZ4irRjeQFKcYGCCM10n7RH7K3hT9pzw74a0DxbqWuQaLod8l+tlplzHGl46rsVZy8bll2lh8pU/OeemOepHng4p2u0vk7XfqtbelzopyUZKTV7XfzWy9Hp958baL8E9T+Fn/BJfx7e3kUz+LfF2nt4l1eVyTMyzSxsA5PPEABYHuz+tR/tTXlhP8A8Ehfh0sDR5m0/QIYFyCWmVV3hff5ZPyNfpBq3hvS9e8O3eg6hYQXejXds1nPYyIDFJCylGjI/ulTjFfMnhH/AIJtfC3wn4g0W6k1jxnr/h7Q706hpHg7W9cNzounz7iweK32A5BJPzM2cnduyaupGNWcltFuD9FBvT7mree5FNypwi3rJc9/NyS1v6rU+j/ANrc2PgXw5bXmftcOm20c27rvEShv1Breooq6kvaTc31M6cPZwjDsrBRRRUGgUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXNeOPiZ4P+GVnbXXjDxXofhS1uXMUE+uajDZpK4GSqtKyhjjnArpa5rxx8M/B/wATbO2tfGHhTQ/FdrbOZYINc06G8SJyMFlWVWCnHGRSd+g1bqctp/7UXwa1a+trKy+LfgW8vbmRYYLe38S2TySyMQFRVEuWYkgADkk16dX5vf8ABLv4O+AfFFj8WNR1nwP4b1bUNH8cTx6bd32k280tkqBWRYXZCYwp5AUjB5Fd/wDtIftdfGX4Nap4mv4/+FM+H9H0ZppLfw14l8SyP4i1a2RjtmgijdEUyINyxnLDOOTxUqpFwhJ6cyT+TSf6j5ZOUkuja+abX6H3FRXxn8WP23PFngv4O/Br406T4a06b4Z+Intx4sgnjmmvtLWbaA8MiuqlVYSLlkOSEHG7jvv2XP2kPEf7S/jj4iaxp1hpkHwh0e9GleH9SWCUXuqToAZpi5k2eUP4QEBO9ecqwrZRfNKPWN7+VrfndW7/AHmfMuWMukrW873/ACs79vmj6OoooqCgooooAKKKKACiiigAqpqurWOg6bc6hqV5b6dYWyGWe6upViiiQdWZ2ICgepNW6+Of+Conwz8cfEn4EaMng7RrzxRa6VrsGo6z4dsWfzdQtEV/kCp8zgMVO1QTzuA+WonLlSfmvld2v8ty4x5nb1+em3z2PWv2Z/2pNB/aWt/GMmlf2fbSaBrt1pUcNrqsd493bRECO9wqrsjlydv3hxwxrvfEPxi8BeEfEVt4f13xv4c0XXrrb5Gl6hq1vBdS7jhdsTuGbJ6YHNfKH7JHxu/Zs+Ini29u/APw+svhl8U9I0q5huNDfS0064aEbGmUeTiOYBo1++PMGCdqgmvA/wBn34N+E/jl+wT8bfip420PT9f8e61JreqjX7yBZry1kgh3xiKQjdGA6k4UgEHByOKqb5U3bSMOZ+ettOmur7J6E017SSjfWUuVeWl9fTRd3dM/Vmsbxd428O+ANHfVvFGvaX4b0pGCNfaveR2sCseAC8jBcn614X/wTv8AGmpePf2NfhrqmrTvdXqWc1iZpDuZ0t7iWBCT3OyNefavL/8Agql8JfCV9+zX418f3eixXfi6zt7CytNSuHeQ2sRvY9whRmKRM29gzIoZhgEkACqxKeHm472dvxsGH/f2vo3+Z9fa18Q/CvhzwmninVvE2j6X4YdI5V1q9v4obJkkx5bCZmCENuXac85GOtcjp/7UXwa1a+trKy+LfgW8vbmRYYLe38S2TySyMQFRVEuWYkgADkk1nfBfwfoPjz9lz4b6L4m0TTfEWjz+GtLaXT9WtI7q3kK28TKWjkBU4IBGRwQDXxp4v+EfgH4rf8FH/BXgDwP4I8N+G/Dvw2tR4g8RTaFpMFn9ouspJFDI0SLvCsbfgn+OX0rWdPkxXsOl2vktW/w/IxjPmw/tutk/m9l97P0qooorE1CiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD5L/4J8/Anxv8DNH+Klv410YaPLrXi241LTwLuGfz7ZlULJ+6dtucHhsN7V8za1+xX8XdNX4z+GP+FMeD/iFqPjHUb2/034o65qtsZ7GKUErHHDIpmSbrtZSqq75LFRmv1NorL2atGPaPL8rL8fdX/DaFqbTb7y5vnr/mz8/tf/Zr+MHjb9m34C/Aefw+2ieF1WB/H2qDUrUm2hhkLraoqylpGYjO5AyghOcbsej/ALEfwV+JH7M/jD4ifDjU9Lku/hIt8+p+Etea9gkKK7DfbNF5hlU4IOSgXdHIc/OM/XVFdCk1OU/5r3872/Kyt873uzHkXJGn0ja3la/531+W1kFFFFQWFFFFABRRRQAUUUUAFeQftLfEj4hfCPwYnizwR4S0rxnp+lrPd67p9/qX2CZbRIy5khlYFAV2ksGBJHQZr1+qup6ZZ61pt3p2o2kF/p93E0Fxa3UayRTRsCrI6MCGUgkEEYINRNScWouzLg4qS5ldHwn8Bvhn41/an/aQ8LftN+LvCWmfDzwxF4dNtpGkW2oLe3mprNFKqzzuqKAuy4fG4BgFQbe9cl4d/Z7/AGjfgX8KfiP8BfBXgbRvE/g/xReXY0zxtPr0Nsum2l0ixyLNasPMdhGP4BwxON4wK/RfR9HsPD2lWmmaVY22mabZxLBbWdnCsUMEajCoiKAFUAAAAYFXK0ko6xivds1bunLm1+fa33ERlK6nJ+8mnfs0rK3yPmKz8B/Fb9mX4NfB/wAAfCDw9ovjSLTrmKy8SXmqzCDyrdjvnuIVM0fJdpCBlyBgbG7cz/wUN8O/GP4vfDnWPhd8P/hN/wAJTo2s21rPL4o/4SSzs/s00dyJDD9lmKs/ES/MHA/ef7NfYdFKpes259Xf/gel1f18h0v3NuTorf8AB9enp5nz/wDszax8VNI+Bg0bxl8KW8Ja54V0i30/SrJfENpfnWmhttoYNGQkG5kUYdsDd97AzXD/APBPf9nPxj8INB8deMfihYx2fxL8ba1Jf6hGLiK4aKEMxRd8bunLvK+FY4DKDyMD64orSU3KpKq95K343b+dtenaxnGCjTjSWyd/0S+V9Ove4UUUVmWFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFea/G/9o74d/s46Tpup/ETxD/wj1jqM7W1rL9iuLrzJAu4riCNyOO5AFJyUdWxpN7HpVFfMmgf8FKv2cPFGu6do2mfEb7TqWo3Mdpaw/wBh6knmSyMERdzWwAyxAySB619N1Vna5N1ewUVkeKvF2heBdDn1nxJrWneHtHtyom1DVbuO2t4yzBV3SOQoySAMnkkCtK1uob62hubaWO4t5kEkc0TBkdSMhlI4II5yKQyWiivKvgd+0d4Z+P1/44tPDtnqlpL4Q1qXQ7/+0oY4xJPGSC0WyR8oSpwW2n2FG7svX8l+qB6av0/N/oz1WiiigAooooAKKKKACiiub+IXxG8M/Cfwne+JvF+t2nh/QrMAzXt4+1QScBQOrMTwFUEk8AGk2oq7Gk27I6Sivlz9jP8Aba0L9qK+8aaW+raOuuabrF5/ZenWUE8Etxo6MqwXLCUnczbvm27cZXKLnn0fxF+1r8IfC3xM0r4e3/jrTm8ZandLYwaTZrJdyLOzBVjlMKssLEkcSFeuelXyu8V1la3z/Xo/PQm6959I3v8AL+vuPXKKK8n+Nf7Vfwo/Z2ms4PiF4zs/D93eL5kFn5M1zcMmSN/lQo7hMgjcQBkEZqG0tykm9j1iivIJP2uPhEvwdufimnjazufAlrMlvcaraQTzmCV2VVjeFEMqNl0+UoCAwJwOa4LQf+ClX7N/ifXNO0fTPiN9p1LULmO0tof7D1JPMlkYIi7mtgBliBkkD1qrNy5bak3XLzdD6cooopDCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD4O/4JPf8i78b/8Ase7r/wBAWjwX8U/j9+2H4s+JmpfDT4h6X8KvB3hHVptF0y3fQIdSm1aaMElp3m/1Sn5DlBwHxtJXJ9b/AGJf2Z/E37Nel/Ea18SahpOoN4j8TT6zZtpUsrhIHUBVk3xph+OQNw9zXnel/sp/Hf4B+MviB/wozxf4JTwd401CTVJLPxhbXX2nSLiTIdrYwqVfGRjzOMIoK8EtzwUlCnHtTS/7eShv/wCTb6XNNLza6zb/AO3W5f8AA87bHzp+0V8dvG37U3/BOHV/FerapbeHr3wz4hXRfE2j2VgkkGryrPb+S6SMxaDYZFchMhiCOBwPqq1u/iR8D/2SLPUvEHxy8Npez/Y5YfFPibQI7WHSbB4EH2eG3gb/AEmdSDs3cvkgjgVTb/gnra2H7E3iD4I2PiXz9f1m5/ta68QXUJWOfUBLHIGZASRHiJE6k4GeTxWd8SP2R/jH8cv2a/DfhLxv4i8E23jnwjrFrqGiyaTBcyaXdQ28HlJHeeau4sxLliibegC8mul2SqRXVwb7bJSa+d3ZWdtFozLeUJLZKaV99243fpp1132PPv2Uv21PE3ir9q3Svhm/xds/jn4T1vTJrhddXwr/AGDPYXUaSOYhHtXeu2PkndneuCMEHtP+CZ//ACNn7TH/AGUO8/8ARkla3gn9lv42at+1l4F+NXxK8ReB7l9G0u50ufR/DEN1DFbRGOVYhAZVJly0zsxcpt6LkdPQf2Qv2b/En7P+tfF688QX+l3sfjDxVca5YrpssjmKB2Yqsu+NMP8ANyF3DjqatW0fXlkn6+0Vv/JV/wAOZyu3ptzRf/kjT/F/8NsfR1FFFZmoUUUUAFFFFABXyl/wUW/Z58ZftBfCLQYvAsVrqWveG9bi1lNFvnVYdRVEdTGd5Ck/MDhiARuGRkV9W14v+1Vq3xO8I/Dq48YfDTW9A06fw3b3Op6np/iOykntr+2jhZym6IiRHXaSNpGScEgVlUkox527WafpZ3v8jWnFylypXvdet1a3zPJf2bf2ztP+Knxet/h78SPhhc/DD4xWdlKtpFfQBkuIAA0i28rKrorCPfsGUZY8h2xXm/7cHhbRvCv7WH7JsOi6RY6RFc+K7i7njsbZIVlmkubRnkYKBudmJJY8knmux/Zg+DXjr45/E/wb+1B8WdW0Iao3h5I/Dvh7w1ayxQWkEyORJM8rMxfbPL8uWGX+9gAVjftFfsy/tN/Gr41+D/Gdtf8AwmtbLwLrE1/4chlm1NJJojKjxi8AjYM2Ikz5bKMlsHpjr/h16MpqzjK8vk3+as7dzn0lSqqDunG0b+cfyT0ufeVfmz+0t4w1v4E/8FCIfHHw70eP4u+LNU8Ltaan4GtIZ3vdNt1VSJ1kjjdYw2xDg/MdzDbiRWr6r8ceHP2i/EHhH4cHQvFfg3wx4ptdRSbxgtpbSy2N5ahvmitDNFI4+X12Ek/fXHPnPjr9l/4veCf2mPFPxk+CviLwc974ssorPVdG8cwXXkR+Wsah4pLfLnPlKcHaBk9eMczT9one1nJX/wC3bfc72v6+prGX7tq26W/+L81a9vTXoc//AMEpU0O8+FnjvXrbV4J/Feu+JbjUNf0KC1e1XRJ2J22wjfnGNxDdP4eqGsPXrhf2sP8AgpZpWjRt9r8EfBi0N7clfmik1VmXC56blk8sY9bZxXr37L/7LHin4AaT8UPE+pa9pfiH4p+PLqTU7p4InttLguR5rRRrwX8vzJnJfbnBAC8c2P2Fv2WNZ/Zl8C+JD4w1Ow13x54n1eXVNX1LTneSJ8/6tA7ojNyXc5UfNI31rdW9tGWyhFW/xWUUl/h1fyWr3Mn/AA5xWvPJrz5b3ba6c23zei2PpeiiisywooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD/9k=)"
      ],
      "metadata": {
        "id": "whcXm-Hq2Km-"
      },
      "id": "whcXm-Hq2Km-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the elements of this image is a type of optical character recognition (OCR).\n",
        "\n",
        "**Task**: Go back to section 3.3 and run OCR on this receipt (the file path is `'ocr/receipt.jpg'`). Notice that each section of text is recognised, but that it does not come back with any information describing what each bit of text means. e.g. it recognises the text \"$0.90\", but it doesn't tell you that that is the price of one apple.\n",
        "\n",
        "We can use a specific service for extracting labelled information from this receipt as shown below."
      ],
      "metadata": {
        "id": "0njIOxAa2LAR"
      },
      "id": "0njIOxAa2LAR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba4b643c-5802-4f2c-94b7-907b08fc66f9",
      "metadata": {
        "id": "ba4b643c-5802-4f2c-94b7-907b08fc66f9"
      },
      "outputs": [],
      "source": [
        "img_fpath = Path('ocr', 'receipt.jpg')\n",
        "with open(img_fpath, 'rb') as f:\n",
        "    response = form_rec_client.begin_recognize_receipts(f)\n",
        "\n",
        "# Collect result from server\n",
        "receipt_data = response.result()\n",
        "# Get data for first receipt (there was only one)\n",
        "receipt = receipt_data[0]\n",
        "\n",
        "# Some convenience methods for printing\n",
        "def conditional_print(key, item):\n",
        "    if item:\n",
        "        print(f'{key}: {item.value}')\n",
        "\n",
        "def get_field_and_print(receipt, field_name):\n",
        "    field = receipt.fields.get(field_name)\n",
        "    conditional_print(field_name, field)\n",
        "\n",
        "# Print out the recognised header\n",
        "get_field_and_print(receipt, 'ReceiptType')\n",
        "get_field_and_print(receipt, 'MerchantAddress')\n",
        "get_field_and_print(receipt, 'MerchantPhoneNumber')\n",
        "get_field_and_print(receipt, 'TransactionDate')\n",
        "\n",
        "# Print out all the recognised items in the receipt\n",
        "items = receipt.fields.get(\"Items\")\n",
        "if items:\n",
        "    for idx, item in enumerate(items.value):\n",
        "        print(f'\\tItem #{idx+1}')\n",
        "        conditional_print(f'\\t - Name', item.value.get('Name'))\n",
        "        conditional_print(f'\\t - Price', item.value.get('Price'))\n",
        "\n",
        "# Print out the recognised footer\n",
        "get_field_and_print(receipt, 'Subtotal')\n",
        "get_field_and_print(receipt, 'Tax')\n",
        "get_field_and_print(receipt, 'Total')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29b1c68e-3a49-4677-9cb0-6d1ae1013dcc",
      "metadata": {
        "id": "29b1c68e-3a49-4677-9cb0-6d1ae1013dcc"
      },
      "source": [
        "# API quiz\n",
        "\n",
        "We've covered a lot of different services that you can call on Azure's systems. We will now review them with a quiz. (Go back to the relevant sections if you need, don't just look at the answers if you can't remember)\n",
        "\n",
        "**Question**: What do each of these api calls do, and what arguments are needed? Write your answers on a piece of paper, in a text document or add a cell to record your answers before you look at the answer.\n",
        "1. `custom_vision_client.classify_image`\n",
        "2. `cog_client.describe_image_in_stream`\n",
        "3. `cog_client.analyze_image_in_stream`\n",
        "4. `cog_client.recognize_printed_text_in_stream`\n",
        "5. Asynchronous:\n",
        "    1. `cog_client.read_in_stream`\n",
        "    2. `cog_client.get_read_result`\n",
        "6. `form_rec_client.begin_recognize_receipts`\n",
        "  \n",
        "\n",
        "<details>\n",
        "<summary style='cursor:pointer;'><u>Answer</u></summary>\n",
        "\n",
        "1. `custom_vision_client.classify_image` is used to send an image to a custom model trained with Azure's Custom Vision projects for classification. It takes one argument: a file stream of the image to classify.\n",
        "2. `cog_client.describe_image_in_stream` is used to caption an image using Cognitive Services. It takes one argument: a file stream of the image.\n",
        "3. `cog_client.analyze_image_in_stream` is used to send an image to Cognitive Services for finding various features of arbitrary objects. It takes two arguments: a file stream of the image and a list of visual_features.\n",
        "4. `cog_client.recognize_printed_text_in_stream` is used to find bounding boxes of text in an image and determine the content of those boxes (OCR). It takes one argument: a file stream of the image.\n",
        "5. Asynchronous:\n",
        "    1. `cog_client.read_in_stream` sends a request to the server to process the image, and returns immediately. It returns an object which can be polled to determine the status of the request. It takes at least one argument: a file stream of the image. When we provide the `raw=True` argument, it includes the HTTP headers in the response which we can parse. In this lab we used it for OCR, but it returns more than just OCR data.\n",
        "    2. `cog_client.get_read_result` polls the server for the status of a request. It takes one argument: the id of the requested operation.\n",
        "9. `form_rec_client.begin_recognize_receipts` is used to extract labelled OCR results from images of receipts with known keys. It takes one argument: a file stream of the image.\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4efd8eea-5729-4aa3-b371-505e50d11429",
      "metadata": {
        "id": "4efd8eea-5729-4aa3-b371-505e50d11429"
      },
      "source": [
        "# Reminder: Shut down resource group\n",
        "\n",
        "Make sure to close down the resource group when you are done. See section 1.2 for instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8fa4ec7-09f7-48fd-a364-45b4fd1c2664",
      "metadata": {
        "id": "d8fa4ec7-09f7-48fd-a364-45b4fd1c2664"
      },
      "source": [
        "# Summary\n",
        "\n",
        "In this lab, you saw how to provision resources on Microsoft Azure's platform, and then interact with those resources with python. You saw several services that are provided out-of-the box from Azure with Cognitive Services, as well as how to train your own classification model with Custom Vision resources."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}